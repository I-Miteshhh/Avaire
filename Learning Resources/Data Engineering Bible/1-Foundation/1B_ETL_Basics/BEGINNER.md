# Week 2: ETL Pipelines & Data Modeling
## ğŸ½ï¸ BEGINNER - The Restaurant Kitchen Edition

---

## ğŸªœ **1. Prerequisites: What You Need to Know First**

Before diving into ETL, let's understand the foundational concepts:

### **A. What is ETL?**

**ETL = Extract, Transform, Load**

Think of it as a **data assembly line**:
- **Extract:** Gather raw ingredients
- **Transform:** Prepare and cook them
- **Load:** Serve the final dish

**Analogy:** A restaurant kitchen!

```
Raw Ingredients (Data Sources)
      â†“ EXTRACT
Kitchen Prep Station (Staging)
      â†“ TRANSFORM
Cooking & Plating (Business Logic)
      â†“ LOAD
Serve to Customers (Data Warehouse)
```

---

### **B. Why Do We Need ETL?**

**Problem:** Data comes from many messy sources:
- Customer database: Oracle
- Sales transactions: MongoDB
- Web logs: JSON files
- Marketing campaigns: Excel sheets

**Reality Check:**
```
âŒ Different formats (JSON, CSV, XML, SQL)
âŒ Different schemas (customer_id vs userId vs cust_no)
âŒ Dirty data (nulls, duplicates, typos)
âŒ Different timezones, currencies, encodings

âœ… Need ONE clean, unified view for analytics!
```

**ETL transforms chaos â†’ clarity**

---

### **C. Where Does Data Come From?**

**Sources (Systems of Record):**

1. **OLTP Databases** (Online Transaction Processing)
   - PostgreSQL, MySQL, Oracle
   - Handle live transactions (orders, payments)
   - Optimized for WRITES

2. **SaaS Applications**
   - Salesforce, Zendesk, Stripe
   - API-based extraction

3. **Files**
   - CSV exports, log files, JSON dumps
   - S3, FTP servers

4. **Streaming**
   - Kafka, Kinesis
   - Real-time events

**Analogy:** Different suppliers delivering ingredients to your restaurant

---

### **D. Where Does Data Go?**

**Destination (Data Warehouse):**

**OLAP Database** (Online Analytical Processing)
- Snowflake, BigQuery, Redshift
- Optimized for READS and complex queries
- Used for analytics, BI dashboards, ML

**Key Difference:**

| OLTP (Source) | OLAP (Destination) |
|---------------|-------------------|
| Many small writes | Few large queries |
| Normalized (less redundancy) | Denormalized (faster reads) |
| Current data | Historical data |
| Row-oriented | Column-oriented |

**Analogy:**
- **OLTP:** Cash register (fast transactions)
- **OLAP:** Accounting ledger (analyze trends)

---

## ğŸ§  **2. ETL Explained Like I'm 10**

### **ğŸ½ï¸ The Restaurant Kitchen Story**

Imagine you run a **fancy restaurant** that sources ingredients from many suppliers:

---

### **STEP 1: EXTRACT (Getting Raw Ingredients)** ğŸ›’

**Morning routine:**
- Baker delivers fresh bread
- Fisherman brings salmon
- Farmer drops off vegetables
- Dairy company ships milk

**Each supplier has different packaging:**
- Bread in paper bags
- Fish in ice boxes
- Vegetables in wooden crates
- Milk in glass bottles

**In data terms:**
```python
# Bread supplier (CSV file)
bread = read_csv("supplier_bread.csv")

# Fish supplier (Database)
fish = query_database("SELECT * FROM fresh_catch")

# Vegetables (JSON API)
veggies = api_call("https://farm.com/api/vegetables")

# Milk (Excel)
milk = read_excel("dairy_delivery.xlsx")
```

**This is EXTRACT!** Gathering data from different sources.

---

### **STEP 2: TRANSFORM (Preparing Ingredients)** ğŸ‘¨â€ğŸ³

**Your kitchen staff cleans and preps:**

**ğŸ¥• Vegetables:**
- Wash dirt off
- Peel and chop
- Remove rotten parts
- Standardize sizes

**ğŸŸ Fish:**
- Remove scales
- Debone
- Cut into portions
- Check for freshness (quality check!)

**ğŸ¥– Bread:**
- Slice evenly
- Toast some, keep some fresh
- Sort by type (sourdough, baguette)

**ğŸ¥› Milk:**
- Check expiration dates
- Standardize temperature
- Measure portions

**In data terms:**
```python
# CLEANING
vegetables = veggies.drop_duplicates()  # Remove duplicates
fish = fish.dropna(subset=['quality'])  # Remove null values

# STANDARDIZATION
bread['price'] = convert_to_usd(bread['price'])  # Same currency
milk['date'] = parse_datetime(milk['delivery_date'])  # Same format

# ENRICHMENT
fish['is_fresh'] = fish['caught_date'] > today - 2_days  # Add flag

# AGGREGATION
total_veggies = vegetables.groupby('type').sum()  # Count by type
```

**This is TRANSFORM!** Cleaning, standardizing, enriching data.

---

### **STEP 3: LOAD (Serving the Meal)** ğŸ½ï¸

**Finally, arrange everything on plates:**
- Place fish in center
- Surround with vegetables
- Add bread on the side
- Pour milk into glasses

**Serve to customers who can now:**
- See the full meal (not raw ingredients!)
- Enjoy a beautiful presentation
- Easily eat and digest

**In data terms:**
```python
# Load into Data Warehouse
final_data.to_sql(
    name='restaurant_inventory',
    con=warehouse_connection,
    if_exists='replace'
)

# Now analysts can query:
SELECT 
    dish_type,
    AVG(customer_rating),
    COUNT(*) as orders
FROM restaurant_inventory
GROUP BY dish_type
```

**This is LOAD!** Putting clean data where analysts can use it.

---

### **The Complete ETL Flow:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         SOURCES (Suppliers)                 â”‚
â”‚  Bread CSV | Fish DB | Veggie API | Milk   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“ EXTRACT
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         STAGING (Delivery Area)             â”‚
â”‚  Raw data temporarily stored                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“ TRANSFORM
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      TRANSFORMATION (Kitchen Prep)          â”‚
â”‚  Clean | Standardize | Validate | Enrich   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“ LOAD
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    DATA WAREHOUSE (Plated Meals)            â”‚
â”‚  Clean, organized data ready for analysis   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ–¼ï¸ **3. Visual Aids: ETL Architecture**

### **Real-World ETL Pipeline:**

```
DATA SOURCES
â”œâ”€â”€ OLTP Databases
â”‚   â”œâ”€â”€ PostgreSQL (Orders)
â”‚   â”œâ”€â”€ MySQL (Customers)
â”‚   â””â”€â”€ MongoDB (Products)
â”‚
â”œâ”€â”€ SaaS APIs
â”‚   â”œâ”€â”€ Salesforce (CRM)
â”‚   â”œâ”€â”€ Stripe (Payments)
â”‚   â””â”€â”€ Google Analytics (Web)
â”‚
â””â”€â”€ Files
    â”œâ”€â”€ S3 Logs (JSON)
    â”œâ”€â”€ FTP CSVs
    â””â”€â”€ Email attachments
         â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   EXTRACT      â”‚
    â”‚  (Connectors)  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   STAGING AREA         â”‚
â”‚  (Temporary Storage)   â”‚
â”‚  - Raw data            â”‚
â”‚  - Minimal processing  â”‚
â”‚  - Short retention     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   TRANSFORM            â”‚
â”‚  1. Clean              â”‚
â”‚     - Remove nulls     â”‚
â”‚     - Fix typos        â”‚
â”‚  2. Standardize        â”‚
â”‚     - Date formats     â”‚
â”‚     - Currencies       â”‚
â”‚  3. Validate           â”‚
â”‚     - Business rules   â”‚
â”‚  4. Enrich             â”‚
â”‚     - Add lookups      â”‚
â”‚  5. Aggregate          â”‚
â”‚     - Roll up data     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   LOAD                 â”‚
â”‚  - Append new records  â”‚
â”‚  - Update existing     â”‚
â”‚  - Handle duplicates   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DATA WAREHOUSE        â”‚
â”‚  (Snowflake/BigQuery)  â”‚
â”‚                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Fact Tables     â”‚ â”‚
â”‚  â”‚  - Sales         â”‚ â”‚
â”‚  â”‚  - Orders        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Dimension Tables â”‚ â”‚
â”‚  â”‚  - Customers     â”‚ â”‚
â”‚  â”‚  - Products      â”‚ â”‚
â”‚  â”‚  - Dates         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¨ **4. Three Powerful Analogies**

### **Analogy 1: The Library System** ğŸ“š

**Extract:**
- Books arrive from different publishers
- Some in boxes, some in bags
- Different languages, sizes, formats

**Transform:**
- Catalog each book
- Add ISBN, Dewey Decimal number
- Repair damaged pages
- Translate titles to library standard
- Sort by category

**Load:**
- Place on correct shelf
- Update computer catalog
- Make available for checkout

**Result:** Patrons can easily find and borrow books!

---

### **Analogy 2: The Laundry Process** ğŸ‘•

**Extract:**
- Collect dirty clothes from different rooms
- Shirts, pants, socks, towels
- Different colors, fabrics, dirt levels

**Transform:**
- Sort by color (whites, colors, darks)
- Check pockets (data quality!)
- Pre-treat stains
- Wash with appropriate settings
- Dry and fold

**Load:**
- Put in closet/drawers
- Organized by type
- Ready to wear

---

### **Analogy 3: The Movie Production** ğŸ¬

**Extract:**
- Film raw footage from multiple cameras
- Audio from different microphones
- Different formats, resolutions, timestamps

**Transform:**
- Sync audio and video
- Color correction
- Cut unnecessary scenes
- Add special effects
- Stabilize shaky footage
- Normalize audio levels

**Load:**
- Export final movie file
- Upload to streaming platform
- Available for viewers

---

## ğŸ§ª **5. Mental Model: Data Modeling Basics**

### **What is a Data Model?**

**Data Model = Blueprint for organizing data**

Think: How should we arrange furniture in a house?

**Two main approaches:**

---

### **Model 1: Star Schema** â­

**Structure:**
- One central **Fact Table** (measurements, events)
- Multiple **Dimension Tables** (descriptive attributes)
- Star shape when visualized

**Example: E-commerce Sales**

```
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  Customer   â”‚
      â”‚ Dimension   â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        â”‚             â”‚
â”‚      SALES FACT        â”‚             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚             â”‚
â”‚  â”‚ sale_id      â”‚     â”‚             â”‚
â”‚  â”‚ customer_id  â”‚â”€â”€â”€â”€â”€â”˜             â”‚
â”‚  â”‚ product_id   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ date_id      â”‚â”€â”€â”€â”€â”€â”€â”€â”   â”‚       â”‚
â”‚  â”‚ amount       â”‚       â”‚   â”‚       â”‚
â”‚  â”‚ quantity     â”‚       â”‚   â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚   â”‚       â”‚
â”‚                         â”‚   â”‚       â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”   â”‚
â”‚                    â”‚   Date     â”‚   â”‚
â”‚                    â”‚ Dimension  â”‚   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”˜
                          â”‚
                    â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
                    â”‚  Product   â”‚
                    â”‚ Dimension  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why "Star"?**
- Fact table in center
- Dimensions radiate out like star points

**Benefits:**
- Simple to understand
- Fast queries (fewer joins)
- Easy for analysts

---

### **Model 2: Snowflake Schema** â„ï¸

**Structure:**
- Same as Star
- But dimensions are **normalized** (broken into sub-tables)

**Example:**

```
      Customer Dimension
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ customer_id  â”‚
      â”‚ city_id      â”‚â”€â”€â”€â”
      â”‚ name         â”‚   â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                         â”‚
                    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ City        â”‚
                    â”‚ city_id     â”‚
                    â”‚ state_id    â”‚â”€â”€â”€â”
                    â”‚ city_name   â”‚   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                                      â”‚
                                 â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
                                 â”‚ State       â”‚
                                 â”‚ state_id    â”‚
                                 â”‚ country_id  â”‚
                                 â”‚ state_name  â”‚
                                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why "Snowflake"?**
- More branches (like snowflake crystals)

**Trade-off:**
- Less storage (no redundancy)
- Slower queries (more joins)
- More complex

---

### **Quick Comparison:**

| Aspect | Star â­ | Snowflake â„ï¸ |
|--------|--------|-------------|
| **Structure** | Denormalized | Normalized |
| **Joins** | Fewer (faster) | More (slower) |
| **Storage** | More space | Less space |
| **Simplicity** | Easy | Complex |
| **Best For** | Analytics | Highly normalized sources |

**Modern Choice:** Most data warehouses use **Star Schema** because:
- Storage is cheap
- Query speed matters
- Simplicity helps analysts

---

## ğŸ¯ **6. Key Concepts Simplified**

### **Concept 1: Fact vs Dimension**

**Fact Table:**
- **What happened** (events, measurements)
- Numeric values (amounts, quantities, counts)
- Large (millions/billions of rows)
- Examples: Sales, Clicks, Transactions

**Dimension Table:**
- **Context** (who, what, when, where, why)
- Descriptive attributes
- Smaller (thousands of rows)
- Examples: Customers, Products, Dates

**Memory Trick:**
- **Facts** = Numbers you measure
- **Dimensions** = Details you describe with

---

### **Concept 2: Batch vs Streaming ETL**

**Batch ETL** (Traditional):
```
Run every night at 2 AM:
  - Extract full day's data
  - Transform everything
  - Load into warehouse
  - Done until tomorrow
```

**Streaming ETL** (Modern):
```
Run continuously:
  - Extract events as they happen
  - Transform in real-time
  - Load immediately
  - Always up-to-date
```

**Analogy:**
- **Batch:** Collect mail once a day
- **Streaming:** Instant message notifications

---

### **Concept 3: Idempotency**

**Big Word, Simple Idea:**

> Running the same operation multiple times produces the same result

**Example:**

**âœ… Idempotent (GOOD):**
```sql
-- Set price to $10
UPDATE products SET price = 10 WHERE id = 123

-- Run twice: Price still $10 âœ“
```

**âŒ Not Idempotent (BAD):**
```sql
-- Increase price by $1
UPDATE products SET price = price + 1 WHERE id = 123

-- Run twice: Price is $12 (not $11!) âœ—
```

**Why This Matters:**
ETL pipelines fail and retry. If not idempotent:
- Data gets corrupted
- Numbers become wrong
- Analytics break

**Golden Rule:** Always design for retries!

---

## âœ… **7. Key Takeaways (BEGINNER Level)**

1. **ETL = Extract, Transform, Load**
   - Extract: Get data from sources
   - Transform: Clean and prepare
   - Load: Put in warehouse

2. **Why ETL?**
   - Unify data from many sources
   - Clean messy data
   - Enable analytics

3. **Data Modeling:**
   - Star Schema: Simple, fast (recommended)
   - Snowflake: Normalized, slower
   - Facts = measurements, Dimensions = context

4. **Batch vs Stream:**
   - Batch: Periodic (nightly)
   - Stream: Continuous (real-time)

5. **Idempotency:**
   - Safe to retry
   - Critical for reliable pipelines

6. **Real-World Example:**
   ```
   Sources: 100 different databases/APIs
   ETL: Runs every hour
   Destination: Single data warehouse
   Users: Analysts, BI dashboards, ML models
   ```

---

## ğŸ¯ **Next Steps**

**You now understand:**
âœ… What ETL is and why it exists  
âœ… The Extract â†’ Transform â†’ Load flow  
âœ… Star vs Snowflake schemas  
âœ… Facts vs Dimensions  

**Next:**
- ğŸ“˜ [INTERMEDIATE](./INTERMEDIATE.md) - Build ETL pipelines in Python
- ğŸ—ï¸ [EXPERT](./EXPERT.md) - Netflix/Airbnb data warehouse design
- ğŸ“„ [WHITEPAPERS](./WHITEPAPERS.md) - Kimball vs Inmon methodologies

---

**"Data is the new oil, but ETL is the refinery."**  
*You just learned how to refine raw data into valuable insights! ğŸ‰*
