# Week 15-16: Production Data Systems â€” EXPERT Track

*"L7+ interviews focus on end-to-end system design at massive scale. You must justify every decision, explain trade-offs, and handle millions of events per second with five-nines availability."* â€” Distinguished Engineer, Amazon

---

## ğŸ¯ Learning Outcomes

- Master FAANG-level system design interviews
- Design real-time analytics platforms (1M+ events/sec)
- Architect multi-region data lakes with consistency
- Implement streaming ETL with exactly-once guarantees
- Design recommendation engines at Netflix scale
- Handle data mesh architectures
- Optimize for $10M+ annual budgets
- Lead architecture reviews and drive decisions

---

## ğŸ—ï¸ 1. FAANG System Design: Real-Time Analytics Platform

### Interview Question (Meta L6+)

```
Design a real-time analytics platform for Instagram Stories that:
- Ingests 10M story views/second (peak: 50M/sec)
- Calculates view counts, unique viewers, engagement metrics
- Provides sub-second query latency for creators
- Handles 2B daily active users
- Ensures exactly-once processing (no double-counting)
- Costs <$5M/year to operate

You have 45 minutes. Go.
```

---

### Solution: Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 1: Data Ingestion (10M events/sec)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚ Mobile Apps (iOS/Android):                                  â”‚
â”‚ â”œâ”€ User views story â†’ Fire event                           â”‚
â”‚ â”œâ”€ Batch events locally (100 events/batch)                 â”‚
â”‚ â””â”€ Send to nearest edge location (CloudFront)              â”‚
â”‚         â”‚                                                   â”‚
â”‚         â–¼                                                   â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚ â”‚ API Gateway (Regional):                â”‚                 â”‚
â”‚ â”‚ â”œâ”€ Rate limiting (1000 req/sec/user)   â”‚                 â”‚
â”‚ â”‚ â”œâ”€ Authentication (JWT validation)     â”‚                 â”‚
â”‚ â”‚ â”œâ”€ Schema validation (Protobuf)        â”‚                 â”‚
â”‚ â”‚ â””â”€ Write to Kafka (async)              â”‚                 â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                  â–¼                                          â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚ â”‚ Kafka Cluster (Multi-Region):          â”‚                 â”‚
â”‚ â”‚ â”œâ”€ 100 partitions (keyed by story_id)  â”‚                 â”‚
â”‚ â”‚ â”œâ”€ Replication factor = 3              â”‚                 â”‚
â”‚ â”‚ â”œâ”€ Retention = 7 days (replay)         â”‚                 â”‚
â”‚ â”‚ â””â”€ Throughput: 50M events/sec          â”‚                 â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                                                              â”‚
â”‚ Cost: API Gateway ($1M/year) + Kafka ($500K/year)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 2: Stream Processing (Flink)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚ Flink Job 1: Real-Time Aggregation                          â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚ â”‚ Kafka â†’ Flink â†’ Redis                  â”‚                 â”‚
â”‚ â”‚                                        â”‚                 â”‚
â”‚ â”‚ Processing:                             â”‚                 â”‚
â”‚ â”‚ 1. Deduplicate (based on event_id)     â”‚                 â”‚
â”‚ â”‚ 2. Window: 5-second tumbling           â”‚                 â”‚
â”‚ â”‚ 3. Aggregate:                           â”‚                 â”‚
â”‚ â”‚    - COUNT(DISTINCT viewer_id)          â”‚                 â”‚
â”‚ â”‚    - SUM(watch_time_seconds)            â”‚                 â”‚
â”‚ â”‚    - COUNT(shares), COUNT(replies)      â”‚                 â”‚
â”‚ â”‚ 4. Write to Redis (story_id â†’ metrics)  â”‚                 â”‚
â”‚ â”‚                                        â”‚                 â”‚
â”‚ â”‚ Exactly-Once:                           â”‚                 â”‚
â”‚ â”‚ â”œâ”€ Flink checkpointing (every 10s)     â”‚                 â”‚
â”‚ â”‚ â”œâ”€ Kafka offset commit in checkpoint   â”‚                 â”‚
â”‚ â”‚ â””â”€ Redis writes idempotent (SET)       â”‚                 â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                                                              â”‚
â”‚ Flink Job 2: Historical Aggregation                         â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚ â”‚ Kafka â†’ Flink â†’ Iceberg (S3)           â”‚                 â”‚
â”‚ â”‚                                        â”‚                 â”‚
â”‚ â”‚ Processing:                             â”‚                 â”‚
â”‚ â”‚ 1. Window: 1-minute tumbling            â”‚                 â”‚
â”‚ â”‚ 2. Aggregate same metrics              â”‚                 â”‚
â”‚ â”‚ 3. Write to Iceberg table:             â”‚                 â”‚
â”‚ â”‚    Partition: story_id, hour            â”‚                 â”‚
â”‚ â”‚    Format: Parquet + Snappy             â”‚                 â”‚
â”‚ â”‚                                        â”‚                 â”‚
â”‚ â”‚ Use case: Historical analysis, ML       â”‚                 â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                                                              â”‚
â”‚ Cluster Size:                                               â”‚
â”‚ â”œâ”€ TaskManagers: 200 (spot instances)                      â”‚
â”‚ â”œâ”€ CPUs: 1600 cores (200 Ã— 8)                              â”‚
â”‚ â”œâ”€ Memory: 12.8 TB (200 Ã— 64 GB)                           â”‚
â”‚ â””â”€ State Backend: RocksDB on SSD                           â”‚
â”‚                                                              â”‚
â”‚ Cost: $2M/year (mostly spot instances)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 3: Serving (Query Layer)                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚ Real-Time Queries (<100ms):                                 â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚ â”‚ Redis Cluster:                          â”‚                 â”‚
â”‚ â”‚ â”œâ”€ 100 nodes (sharded by story_id)     â”‚                 â”‚
â”‚ â”‚ â”œâ”€ 10 TB total memory                   â”‚                 â”‚
â”‚ â”‚ â”œâ”€ Replication: 2 replicas/shard       â”‚                 â”‚
â”‚ â”‚ â””â”€ Query: GET story:12345:metrics       â”‚                 â”‚
â”‚ â”‚    â†’ {views: 1000000, unique: 500000}   â”‚                 â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                                                              â”‚
â”‚ Historical Queries (1-10 seconds):                          â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚ â”‚ Presto/Trino (Query Engine):            â”‚                 â”‚
â”‚ â”‚ â”œâ”€ 50 worker nodes                      â”‚                 â”‚
â”‚ â”‚ â”œâ”€ Read from Iceberg table (S3)        â”‚                 â”‚
â”‚ â”‚ â”œâ”€ Partition pruning (story_id, hour)   â”‚                 â”‚
â”‚ â”‚ â””â”€ Query: SELECT SUM(views) FROM ...    â”‚                 â”‚
â”‚ â”‚    WHERE story_id = 12345               â”‚                 â”‚
â”‚ â”‚    AND hour >= '2025-10-01'             â”‚                 â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                                                              â”‚
â”‚ Cost: Redis ($800K/year) + Presto ($500K/year)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 4: Monitoring & Observability                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚ Metrics:                                                     â”‚
â”‚ â”œâ”€ Prometheus (scrape Flink, Kafka, Redis)                 â”‚
â”‚ â”œâ”€ Grafana dashboards (P50/P95/P99 latency)                â”‚
â”‚ â””â”€ Alerting: PagerDuty (SLA violations)                    â”‚
â”‚                                                              â”‚
â”‚ Tracing:                                                     â”‚
â”‚ â”œâ”€ Jaeger (distributed tracing)                             â”‚
â”‚ â”œâ”€ Trace ID: Follow event from app â†’ Kafka â†’ Flink â†’ Redis â”‚
â”‚ â””â”€ Debug slow queries                                       â”‚
â”‚                                                              â”‚
â”‚ Logging:                                                     â”‚
â”‚ â”œâ”€ Elasticsearch (centralized logs)                         â”‚
â”‚ â”œâ”€ Kibana (search, visualize)                              â”‚
â”‚ â””â”€ Retention: 30 days                                       â”‚
â”‚                                                              â”‚
â”‚ Cost: $200K/year                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

TOTAL COST: $1M + $0.5M + $2M + $0.8M + $0.5M + $0.2M
          = $5M/year âœ… (within budget)
```

---

### Deep Dive: Exactly-Once Processing

```python
# Flink job with exactly-once semantics

from pyflink.datastream import StreamExecutionEnvironment
from pyflink.datastream.connectors import FlinkKafkaConsumer, FlinkKafkaProducer
from pyflink.datastream.checkpoint import CheckpointingMode

env = StreamExecutionEnvironment.get_execution_environment()

# Enable checkpointing (exactly-once)
env.enable_checkpointing(10000)  # 10 seconds
env.get_checkpoint_config().set_checkpointing_mode(CheckpointingMode.EXACTLY_ONCE)
env.get_checkpoint_config().set_checkpoint_storage_dir('s3://checkpoints/')

# State backend (RocksDB for large state)
env.set_state_backend(RocksDBStateBackend('s3://state/'))

# Kafka consumer (read from earliest on first run)
kafka_consumer = FlinkKafkaConsumer(
    topics='story-views',
    deserialization_schema=JsonDeserializationSchema(),
    properties={
        'bootstrap.servers': 'kafka:9092',
        'group.id': 'flink-aggregator',
        'enable.auto.commit': 'false',  # Manual offset management
    }
)
kafka_consumer.set_start_from_earliest()

# Deduplication with state
class DeduplicateFunction(KeyedProcessFunction):
    def open(self, runtime_context):
        # TTL state (expire after 1 hour)
        state_descriptor = ValueStateDescriptor(
            'seen_events',
            Types.BOOLEAN(),
        )
        state_descriptor.enable_time_to_live(
            StateTtlConfig.new_builder(Time.hours(1))
                .set_update_type(StateTtlConfig.UpdateType.OnCreateAndWrite)
                .build()
        )
        self.seen_state = runtime_context.get_state(state_descriptor)
    
    def process_element(self, value, ctx):
        event_id = value['event_id']
        
        # Check if seen before
        if self.seen_state.value():
            return  # Skip duplicate
        
        # Mark as seen
        self.seen_state.update(True)
        
        # Emit
        yield value

# Aggregation with windowing
aggregated = (
    env.add_source(kafka_consumer)
    .key_by(lambda x: x['story_id'])
    .process(DeduplicateFunction())
    .key_by(lambda x: x['story_id'])
    .window(TumblingEventTimeWindows.of(Time.seconds(5)))
    .aggregate(
        AggregateFunction(
            create_accumulator=lambda: {'views': 0, 'unique_viewers': set()},
            add=lambda acc, value: {
                'views': acc['views'] + 1,
                'unique_viewers': acc['unique_viewers'] | {value['viewer_id']},
            },
            get_result=lambda acc: {
                'views': acc['views'],
                'unique_viewers': len(acc['unique_viewers']),
            },
            merge=lambda acc1, acc2: {
                'views': acc1['views'] + acc2['views'],
                'unique_viewers': acc1['unique_viewers'] | acc2['unique_viewers'],
            },
        )
    )
)

# Sink to Redis (exactly-once via checkpointing)
redis_sink = RedisSink(
    redis_host='redis-cluster',
    key_template='story:{story_id}:metrics',
    value_serializer=JsonSerializer(),
)

aggregated.add_sink(redis_sink)

env.execute('Story Views Aggregation')
```

**How exactly-once works:**

1. **Checkpoint Coordination:**
   - Flink injects barriers into stream every 10 seconds
   - Barriers flow through pipeline (source â†’ operators â†’ sink)
   - When operator receives barrier: Take snapshot of state

2. **Atomic Commit:**
   - When all operators complete checkpoint:
     - Kafka offsets committed
     - Redis writes committed
     - State snapshots saved to S3
   - If any operator fails: Rollback entire checkpoint

3. **Recovery:**
   - On failure: Restore from last checkpoint
   - Kafka: Rewind to committed offsets
   - Redis: Idempotent writes (SET overwrites)
   - State: Restore from S3

---

### Deep Dive: Cost Optimization

```
Initial Design (Naive): $15M/year
â”œâ”€ Always-on Flink cluster (200 nodes Ã— $5/hour Ã— 8760 hours)
â”œâ”€ Redis with 3 replicas (300 nodes Ã— $2/hour Ã— 8760 hours)
â””â”€ Premium S3 storage (100 TB Ã— $0.023/GB Ã— 12 months)

Optimized Design: $5M/year (67% savings)

1. Flink: Spot Instances + Autoscaling
   â”œâ”€ Use spot instances (70% discount)
   â”œâ”€ Autoscale based on Kafka lag (50-200 nodes)
   â”œâ”€ Cost: 125 avg nodes Ã— $1.5/hour Ã— 8760 = $1.6M/year
   â””â”€ Savings: $8.7M - $1.6M = $7.1M âœ…

2. Redis: Memory Optimization
   â”œâ”€ Compress metrics (JSON â†’ MessagePack): 50% smaller
   â”œâ”€ Use Redis Cluster (vs Enterprise): 40% cheaper
   â”œâ”€ Expire old data (TTL = 7 days): 80% less memory
   â”œâ”€ Cost: 30 nodes Ã— $2/hour Ã— 8760 = $525K/year
   â””â”€ Savings: $5.2M - $525K = $4.7M âœ…

3. S3: Lifecycle Policies
   â”œâ”€ Hot (last 7 days): Standard (10 TB Ã— $23/month)
   â”œâ”€ Warm (8-30 days): S3-IA (20 TB Ã— $12.5/month)
   â”œâ”€ Cold (31-365 days): Glacier (100 TB Ã— $4/month)
   â”œâ”€ Archive (>365 days): Glacier Deep (200 TB Ã— $1/month)
   â”œâ”€ Cost: $230 + $250 + $400 + $200 = $1080/month = $13K/year
   â””â”€ Savings: $276K - $13K = $263K âœ…

4. Network: VPC Endpoints
   â”œâ”€ Avoid NAT Gateway ($0.045/GB): Use VPC endpoints
   â”œâ”€ Compress before transfer (Snappy): 3x smaller
   â”œâ”€ Cost: $50K/year
   â””â”€ Savings: $500K - $50K = $450K âœ…

5. Kafka: Tiered Storage
   â”œâ”€ Hot (last 7 days): Local SSD (fast, expensive)
   â”œâ”€ Cold (8-90 days): S3 tiered storage (slow, cheap)
   â”œâ”€ Cost: $300K/year
   â””â”€ Savings: $800K - $300K = $500K âœ…

Total Savings: $7.1M + $4.7M + $263K + $450K + $500K = $13M
Final Cost: $15M - $13M = $2M/year (with $3M buffer)
```

---

## ğŸŒ 2. System Design: Multi-Region Data Lake

### Interview Question (AWS L7+)

```
Design Airbnb's data lake that:
- Stores 500 PB of data (listings, bookings, reviews, events)
- Supports 10K analysts running SQL queries
- Handles 100M events/day from 7M listings
- Multi-region (US, EU, APAC) with <1 second latency
- Complies with GDPR (EU data stays in EU)
- Costs <$10M/year

45 minutes. Design, justify, optimize.
```

---

### Solution: Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Region 1: US (Primary)                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚ Data Sources:                                                â”‚
â”‚ â”œâ”€ Application databases (RDS, DynamoDB)                    â”‚
â”‚ â”œâ”€ Kafka streams (user events, bookings)                    â”‚
â”‚ â””â”€ Third-party APIs (payment providers)                     â”‚
â”‚         â”‚                                                    â”‚
â”‚         â–¼                                                    â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚ â”‚ Ingestion Layer:                       â”‚                  â”‚
â”‚ â”‚ â”œâ”€ Firehose â†’ S3 (clickstream)         â”‚                  â”‚
â”‚ â”‚ â”œâ”€ DMS â†’ S3 (CDC from RDS)             â”‚                  â”‚
â”‚ â”‚ â””â”€ Lambda â†’ S3 (API polling)           â”‚                  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                  â–¼                                           â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚ â”‚ S3 Data Lake (Iceberg):                â”‚                  â”‚
â”‚ â”‚ â”œâ”€ Raw zone: JSON/Avro (7 days)        â”‚                  â”‚
â”‚ â”‚ â”œâ”€ Cleaned zone: Parquet (90 days)     â”‚                  â”‚
â”‚ â”‚ â”œâ”€ Curated zone: Aggregated (365 days) â”‚                  â”‚
â”‚ â”‚ â””â”€ Archive zone: Glacier (7 years)     â”‚                  â”‚
â”‚ â”‚                                        â”‚                  â”‚
â”‚ â”‚ Partitioning: region, date, entity     â”‚                  â”‚
â”‚ â”‚ Size: 200 PB (US listings + bookings)  â”‚                  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                  â–¼                                           â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚ â”‚ Query Engines:                          â”‚                  â”‚
â”‚ â”‚ â”œâ”€ Presto (ad-hoc queries)             â”‚                  â”‚
â”‚ â”‚ â”œâ”€ Spark (batch ETL)                   â”‚                  â”‚
â”‚ â”‚ â””â”€ Athena (serverless queries)         â”‚                  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Region 2: EU (GDPR Compliant)                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚ Data Sources:                                                â”‚
â”‚ â”œâ”€ EU-only data (listings, users, bookings in EU)          â”‚
â”‚ â””â”€ NO cross-region transfer (GDPR requirement)              â”‚
â”‚         â”‚                                                    â”‚
â”‚         â–¼                                                    â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚ â”‚ S3 Data Lake (EU-only):                â”‚                  â”‚
â”‚ â”‚ â”œâ”€ Encrypted with EU KMS keys           â”‚                  â”‚
â”‚ â”‚ â”œâ”€ Access restricted to EU resources    â”‚                  â”‚
â”‚ â”‚ â””â”€ Size: 150 PB (EU listings)           â”‚                  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                  â–¼                                           â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚ â”‚ Query Engines (EU-only):                â”‚                  â”‚
â”‚ â”‚ â”œâ”€ Presto cluster (EU analysts)         â”‚                  â”‚
â”‚ â”‚ â””â”€ Athena (EU compliance team)          â”‚                  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Region 3: APAC                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Similar to US, size: 150 PB                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Global Query Federation:                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚ Trino Coordinator (Global):                                 â”‚
â”‚ â”œâ”€ Query: "SELECT COUNT(*) FROM bookings"                   â”‚
â”‚ â”œâ”€ Plan: Federate across US + EU + APAC                    â”‚
â”‚ â”œâ”€ Execute: Workers read local S3                          â”‚
â”‚ â””â”€ Merge results from 3 regions                            â”‚
â”‚                                                              â”‚
â”‚ GDPR Enforcement:                                            â”‚
â”‚ â”œâ”€ Query: "SELECT * FROM users WHERE region = 'EU'"         â”‚
â”‚ â”œâ”€ Plan: Only read from EU data lake                       â”‚
â”‚ â””â”€ Block: Cannot export EU data to non-EU regions           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Deep Dive: GDPR Compliance

```python
# Trino query planner with GDPR enforcement

class GDPRQueryPlanner:
    def plan_query(self, sql, user_region):
        """
        Enforce GDPR: EU data cannot leave EU
        """
        # Parse SQL
        query = parse_sql(sql)
        
        # Extract referenced tables
        tables = extract_tables(query)
        
        # Check data residency
        for table in tables:
            table_region = get_table_region(table)
            
            if table_region == 'EU' and user_region != 'EU':
                # GDPR violation: EU data accessed from non-EU
                raise GDPRViolation(
                    f"Cannot access EU table '{table}' from region '{user_region}'"
                )
            
            if table_region == 'EU':
                # Ensure query runs in EU region only
                query_region = 'EU'
            else:
                query_region = user_region
        
        # Plan execution
        plan = {
            'query': sql,
            'region': query_region,
            'workers': get_workers(query_region),
            's3_paths': [f's3://{query_region}-data-lake/{table}' for table in tables],
        }
        
        return plan

# Example: Compliant query
plan = GDPRQueryPlanner().plan_query(
    sql="SELECT COUNT(*) FROM eu_users WHERE country = 'France'",
    user_region='EU',
)
# Result: Run in EU region âœ…

# Example: Blocked query
plan = GDPRQueryPlanner().plan_query(
    sql="SELECT * FROM eu_users",
    user_region='US',
)
# Result: GDPRViolation exception âŒ
```

---

### Deep Dive: Cost Breakdown

```
Total Cost: $10M/year

1. Storage (S3):
   â”œâ”€ 500 PB total
   â”œâ”€ Hot (7 days): 5 PB Ã— $23/TB/month = $115K/month
   â”œâ”€ Warm (90 days): 50 PB Ã— $12.5/TB/month = $625K/month
   â”œâ”€ Cold (365 days): 200 PB Ã— $4/TB/month = $800K/month
   â”œâ”€ Archive (7 years): 245 PB Ã— $1/TB/month = $245K/month
   â””â”€ Total: $1.785M/month = $21.4M/year âŒ Over budget!
   
   Optimization:
   â”œâ”€ Compress with Zstd: 500 PB â†’ 150 PB (3x compression)
   â”œâ”€ Deduplicate: 150 PB â†’ 120 PB (20% dedup)
   â”œâ”€ Delete old data: 120 PB â†’ 100 PB (retention policy)
   â””â”€ Cost: 100 PB Ã— weighted avg ($5/TB/month) = $500K/month = $6M/year âœ…

2. Compute (Presto/Spark):
   â”œâ”€ 100 nodes Ã— $2/hour Ã— 8760 hours = $1.75M/year âŒ
   
   Optimization:
   â”œâ”€ Autoscale: 20-100 nodes (avg 40 nodes)
   â”œâ”€ Spot instances (70% discount)
   â”œâ”€ Cost: 40 nodes Ã— $0.6/hour Ã— 8760 = $210K/year âœ…

3. Network:
   â”œâ”€ Cross-region queries: 10 TB/day Ã— $0.02/GB Ã— 365 = $73K/year
   â”œâ”€ Optimization: Use S3 replication (cheaper)
   â””â”€ Cost: $50K/year âœ…

4. Metadata (Glue Catalog):
   â”œâ”€ 100M objects Ã— $1/million/month = $100/month = $1.2K/year âœ…

5. Monitoring:
   â”œâ”€ CloudWatch, X-Ray, Grafana
   â””â”€ Cost: $100K/year âœ…

Total: $6M + $210K + $50K + $1.2K + $100K = $6.36M/year âœ… (36% under budget)
```

---

## ğŸ¬ 3. System Design: Recommendation Engine (Netflix Scale)

### Interview Question (Netflix L8+)

```
Design Netflix's recommendation engine that:
- Serves 200M subscribers
- Generates personalized recommendations in <200ms
- Processes 1B viewing events/day
- Trains ML models on 10 years of data (100 PB)
- A/B tests 100+ models simultaneously
- Costs <$20M/year

60 minutes. Focus on ML pipeline + serving infrastructure.
```

---

### Solution: Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Offline Layer: ML Training                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚ Data Lake (Iceberg):                                         â”‚
â”‚ â”œâ”€ 100 PB historical data (10 years)                        â”‚
â”‚ â”œâ”€ 1B events/day (watch, pause, rewind, skip)              â”‚
â”‚ â””â”€ Partitioned by date, user_segment                        â”‚
â”‚         â”‚                                                    â”‚
â”‚         â–¼                                                    â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚ â”‚ Feature Engineering (Spark):            â”‚                  â”‚
â”‚ â”‚ â”œâ”€ User features:                       â”‚                  â”‚
â”‚ â”‚ â”‚  â”œâ”€ Watch history (last 90 days)      â”‚                  â”‚
â”‚ â”‚ â”‚  â”œâ”€ Genre preferences                 â”‚                  â”‚
â”‚ â”‚ â”‚  â””â”€ Time-of-day patterns              â”‚                  â”‚
â”‚ â”‚ â”œâ”€ Item features:                       â”‚                  â”‚
â”‚ â”‚  â”œâ”€ Metadata (genre, cast, director)   â”‚                  â”‚
â”‚ â”‚  â”œâ”€ Popularity metrics                  â”‚                  â”‚
â”‚ â”‚  â””â”€ Engagement scores                   â”‚                  â”‚
â”‚ â”‚ â””â”€ Interaction features:                â”‚                  â”‚
â”‚ â”‚    â”œâ”€ Collaborative filtering           â”‚                  â”‚
â”‚ â”‚    â””â”€ Content-based filtering           â”‚                  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                  â–¼                                           â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚ â”‚ Model Training (TensorFlow):            â”‚                  â”‚
â”‚ â”‚ â”œâ”€ Two-Tower DNN (user Ã— item)          â”‚                  â”‚
â”‚ â”‚ â”œâ”€ Training:                            â”‚                  â”‚
â”‚ â”‚ â”‚  â”œâ”€ 1000 GPU cluster (A100)           â”‚                  â”‚
â”‚ â”‚ â”‚  â”œâ”€ Distributed training (Horovod)    â”‚                  â”‚
â”‚ â”‚ â”‚  â””â”€ 7 days to train 1 model           â”‚                  â”‚
â”‚ â”‚ â”œâ”€ Hyperparameter tuning (Optuna)       â”‚                  â”‚
â”‚ â”‚ â””â”€ Model versioning (MLflow)            â”‚                  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                  â–¼                                           â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚ â”‚ Model Evaluation:                       â”‚                  â”‚
â”‚ â”‚ â”œâ”€ Offline metrics:                     â”‚                  â”‚
â”‚ â”‚ â”‚  â”œâ”€ AUC, Precision@K, Recall@K        â”‚                  â”‚
â”‚ â”‚ â”‚  â””â”€ NDCG (ranking quality)            â”‚                  â”‚
â”‚ â”‚ â”œâ”€ A/B test framework:                  â”‚                  â”‚
â”‚ â”‚ â”‚  â”œâ”€ Deploy to 1% of users             â”‚                  â”‚
â”‚ â”‚ â”‚  â”œâ”€ Measure watch time, engagement    â”‚                  â”‚
â”‚ â”‚ â”‚  â””â”€ Promote if +2% watch time         â”‚                  â”‚
â”‚ â”‚ â””â”€ Shadow testing (log predictions)     â”‚                  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                                                              â”‚
â”‚ Cost: $8M/year (GPU training + Spark)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Online Layer: Real-Time Serving                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚ â”‚ User Request:                           â”‚                  â”‚
â”‚ â”‚ "Show homepage recommendations"         â”‚                  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                  â–¼                                           â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚ â”‚ API Gateway + Feature Store:            â”‚                  â”‚
â”‚ â”‚ â”œâ”€ Get user features (DynamoDB):        â”‚                  â”‚
â”‚ â”‚ â”‚  â”œâ”€ user_id â†’ watch_history           â”‚                  â”‚
â”‚ â”‚ â”‚  â””â”€ Cached in Redis (10M users)       â”‚                  â”‚
â”‚ â”‚ â”œâ”€ Get item features (Cassandra):       â”‚                  â”‚
â”‚ â”‚ â”‚  â”œâ”€ 100K titles Ã— 500 features        â”‚                  â”‚
â”‚ â”‚ â”‚  â””â”€ Precomputed, updated hourly       â”‚                  â”‚
â”‚ â”‚ â””â”€ Latency: 20ms                        â”‚                  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                  â–¼                                           â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚ â”‚ Candidate Generation:                   â”‚                  â”‚
â”‚ â”‚ â”œâ”€ Retrieve top 1000 candidates         â”‚                  â”‚
â”‚ â”‚ â”œâ”€ Methods:                             â”‚                  â”‚
â”‚ â”‚ â”‚  â”œâ”€ Collaborative filtering (ANN)     â”‚                  â”‚
â”‚ â”‚ â”‚  â”œâ”€ Content-based (similar titles)    â”‚                  â”‚
â”‚ â”‚ â”‚  â””â”€ Trending (popular today)          â”‚                  â”‚
â”‚ â”‚ â””â”€ Latency: 50ms                        â”‚                  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                  â–¼                                           â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚ â”‚ Ranking (TensorFlow Serving):           â”‚                  â”‚
â”‚ â”‚ â”œâ”€ Score 1000 candidates                â”‚                  â”‚
â”‚ â”‚ â”œâ”€ Model: Two-Tower DNN                 â”‚                  â”‚
â”‚ â”‚ â”œâ”€ Batch inference (100 items/batch)    â”‚                  â”‚
â”‚ â”‚ â”œâ”€ Return top 50 ranked items           â”‚                  â”‚
â”‚ â”‚ â””â”€ Latency: 100ms                       â”‚                  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                  â–¼                                           â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚ â”‚ Post-Processing:                        â”‚                  â”‚
â”‚ â”‚ â”œâ”€ Diversity (avoid same genre)         â”‚                  â”‚
â”‚ â”‚ â”œâ”€ Freshness (mix old + new titles)     â”‚                  â”‚
â”‚ â”‚ â”œâ”€ Business rules (promote originals)   â”‚                  â”‚
â”‚ â”‚ â””â”€ Latency: 10ms                        â”‚                  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                  â–¼                                           â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚ â”‚ Response:                               â”‚                  â”‚
â”‚ â”‚ [Title1, Title2, ..., Title50]          â”‚                  â”‚
â”‚ â”‚ Total Latency: 20+50+100+10 = 180ms âœ…  â”‚                  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                                                              â”‚
â”‚ Infrastructure:                                              â”‚
â”‚ â”œâ”€ TF Serving: 500 instances (CPU)                          â”‚
â”‚ â”œâ”€ Feature Store: 200 DynamoDB nodes                        â”‚
â”‚ â”œâ”€ Candidate Gen: 100 instances (CPU + ANN index)           â”‚
â”‚ â””â”€ Cost: $10M/year                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

TOTAL COST: $8M (offline) + $10M (online) = $18M/year âœ…
```

---

### Deep Dive: ANN for Candidate Generation

```python
# Approximate Nearest Neighbor (ANN) for fast retrieval

import faiss
import numpy as np

# 1. Build index (offline)
class ANNIndex:
    def __init__(self, embedding_dim=128):
        self.embedding_dim = embedding_dim
        
        # HNSW index (Hierarchical Navigable Small World)
        self.index = faiss.IndexHNSWFlat(embedding_dim, 32)
        self.index.hnsw.efConstruction = 40
        self.item_ids = []
    
    def build(self, item_embeddings):
        """
        item_embeddings: dict {item_id: embedding (128-dim vector)}
        """
        # Convert to numpy array
        item_ids = list(item_embeddings.keys())
        embeddings = np.array([item_embeddings[id] for id in item_ids], dtype='float32')
        
        # Add to index
        self.index.add(embeddings)
        self.item_ids = item_ids
        
        print(f"Built index with {len(item_ids)} items")
    
    def search(self, user_embedding, k=1000):
        """
        Find k nearest items to user embedding
        """
        # Search index
        distances, indices = self.index.search(
            np.array([user_embedding], dtype='float32'),
            k
        )
        
        # Map indices to item IDs
        candidates = [(self.item_ids[idx], distances[0][i]) 
                      for i, idx in enumerate(indices[0])]
        
        return candidates

# 2. Online serving
ann_index = ANNIndex()
ann_index.load_from_disk('/models/ann_index.faiss')

def get_recommendations(user_id):
    # Get user embedding (from feature store)
    user_embedding = feature_store.get_user_embedding(user_id)
    
    # Search ANN index (50ms)
    candidates = ann_index.search(user_embedding, k=1000)
    
    # candidates = [(item_id, distance), ...]
    return [item_id for item_id, _ in candidates]

# Performance:
# â”œâ”€ Brute-force (dot product with 100K items): 500ms
# â””â”€ HNSW ANN (approximate): 50ms âœ… (10x faster, 99% recall)
```

---

## ğŸ“š Summary: FAANG Interview Checklist

### System Design Framework (45-60 minutes)

```
1. Clarify Requirements (5 min):
   â”œâ”€ Functional: What features? (read-heavy vs write-heavy)
   â”œâ”€ Non-functional: Scale? Latency? Availability?
   â””â”€ Constraints: Budget? Existing infrastructure?

2. High-Level Design (10 min):
   â”œâ”€ Draw boxes: Client â†’ API â†’ Processing â†’ Storage
   â”œâ”€ Identify bottlenecks
   â””â”€ Choose technologies (justify each choice)

3. Deep Dive (20 min):
   â”œâ”€ Pick 2-3 components to detail
   â”œâ”€ Examples:
   â”‚  â”œâ”€ How does exactly-once work?
   â”‚  â”œâ”€ How do you handle hot partitions?
   â”‚  â””â”€ How do you ensure GDPR compliance?
   â””â”€ Show code/pseudocode if helpful

4. Trade-Offs (5 min):
   â”œâ”€ Explain alternatives considered
   â”œâ”€ Justify final decisions
   â””â”€ Example: "Chose Kafka over Kinesis because..."

5. Optimizations (5 min):
   â”œâ”€ Performance: Caching, indexing, partitioning
   â”œâ”€ Cost: Spot instances, lifecycle policies
   â””â”€ Reliability: Multi-region, backups

6. Monitoring (3 min):
   â”œâ”€ Metrics to track (latency, errors, throughput)
   â”œâ”€ Alerts (SLA violations)
   â””â”€ Debugging (tracing, logging)

7. Q&A (7 min):
   â”œâ”€ Answer follow-up questions
   â””â”€ Admit unknowns ("I'd research X before implementing")
```

---

### Common Pitfalls to Avoid

```
âŒ Don't:
â”œâ”€ Jump into implementation without clarifying requirements
â”œâ”€ Over-engineer (add complexity without justification)
â”œâ”€ Ignore trade-offs (every decision has pros/cons)
â”œâ”€ Forget about cost (unlimited budget doesn't exist)
â”œâ”€ Neglect monitoring (how do you know it works?)
â””â”€ Use buzzwords without understanding (e.g., "microservices solve everything")

âœ… Do:
â”œâ”€ Ask clarifying questions early
â”œâ”€ Start simple, then scale
â”œâ”€ Justify every technology choice
â”œâ”€ Mention cost at least once
â”œâ”€ Discuss monitoring and alerting
â””â”€ Show deep understanding of 2-3 technologies
```

---

**Next:** [WHITEPAPERS.md â†’](WHITEPAPERS.md)
