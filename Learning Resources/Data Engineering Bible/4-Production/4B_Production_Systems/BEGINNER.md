# Week 15-16: Production Data Systems â€” BEGINNER Track

*"The difference between a proof-of-concept and a production system is 10x the effort. Understanding patterns, anti-patterns, and monitoring fundamentals is essential for L5+ engineers."* â€” Principal Engineer, Google

---

## ðŸŽ¯ Learning Outcomes

- Understand production vs development environments
- Identify common data platform patterns (Lambda, Kappa, batch, streaming)
- Recognize anti-patterns and their consequences
- Implement monitoring and observability
- Design alerting strategies
- Handle data quality at scale
- Understand SLAs, SLIs, and SLOs
- Build fault-tolerant systems

---

## ðŸ—ï¸ 1. Production vs Development

### Key Differences

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Aspect           â”‚ Development         â”‚ Production          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Data Volume      â”‚ Sample (1K rows)    â”‚ Full (1B+ rows)     â”‚
â”‚ Availability     â”‚ Best effort         â”‚ 99.9%+ SLA          â”‚
â”‚ Performance      â”‚ "Works on my        â”‚ P50/P95/P99 metrics â”‚
â”‚                  â”‚ laptop"             â”‚ defined             â”‚
â”‚ Error Handling   â”‚ Print to console    â”‚ Structured logging, â”‚
â”‚                  â”‚                     â”‚ alerting            â”‚
â”‚ Monitoring       â”‚ None                â”‚ Dashboards, metrics â”‚
â”‚ Cost             â”‚ Free tier           â”‚ Optimized ($1000s)  â”‚
â”‚ Deployment       â”‚ Manual              â”‚ CI/CD, blue-green   â”‚
â”‚ Rollback         â”‚ Git reset           â”‚ Automated rollback  â”‚
â”‚ Testing          â”‚ Manual              â”‚ Unit + integration  â”‚
â”‚                  â”‚                     â”‚ + load tests        â”‚
â”‚ Documentation    â”‚ Optional            â”‚ Required (runbooks) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Production Readiness Checklist

```
Infrastructure:
â”œâ”€ [ ] Multi-region deployment (disaster recovery)
â”œâ”€ [ ] Autoscaling configured (handle traffic spikes)
â”œâ”€ [ ] Load balancing (distribute traffic)
â”œâ”€ [ ] Health checks (liveness/readiness probes)
â””â”€ [ ] Resource limits (CPU, memory, disk quotas)

Observability:
â”œâ”€ [ ] Logging (structured logs to centralized system)
â”œâ”€ [ ] Metrics (Prometheus, Datadog, CloudWatch)
â”œâ”€ [ ] Tracing (distributed tracing with Jaeger/Zipkin)
â”œâ”€ [ ] Dashboards (Grafana, Kibana for visualization)
â””â”€ [ ] Alerting (PagerDuty, Slack, email on errors)

Reliability:
â”œâ”€ [ ] Error handling (retry with exponential backoff)
â”œâ”€ [ ] Circuit breakers (prevent cascading failures)
â”œâ”€ [ ] Timeouts (avoid hanging requests)
â”œâ”€ [ ] Rate limiting (protect from abuse)
â””â”€ [ ] Graceful degradation (partial functionality on failure)

Data Quality:
â”œâ”€ [ ] Schema validation (reject invalid data)
â”œâ”€ [ ] Duplicate detection (idempotency)
â”œâ”€ [ ] Data reconciliation (source vs destination counts)
â”œâ”€ [ ] Data lineage (track data provenance)
â””â”€ [ ] SLA monitoring (data freshness, completeness)

Security:
â”œâ”€ [ ] Authentication (API keys, OAuth, mTLS)
â”œâ”€ [ ] Authorization (RBAC, least privilege)
â”œâ”€ [ ] Encryption at rest (KMS, customer-managed keys)
â”œâ”€ [ ] Encryption in transit (TLS 1.2+)
â””â”€ [ ] Audit logging (who accessed what, when)

Testing:
â”œâ”€ [ ] Unit tests (>80% code coverage)
â”œâ”€ [ ] Integration tests (end-to-end workflows)
â”œâ”€ [ ] Load tests (simulate production traffic)
â”œâ”€ [ ] Chaos testing (inject failures, test resilience)
â””â”€ [ ] Canary deployments (gradual rollout)

Operations:
â”œâ”€ [ ] Runbooks (how to debug common issues)
â”œâ”€ [ ] Incident response plan (on-call rotation)
â”œâ”€ [ ] Backup & restore (automated daily backups)
â”œâ”€ [ ] Disaster recovery plan (RTO/RPO targets)
â””â”€ [ ] Cost monitoring (budget alerts)
```

---

## ðŸ“ 2. Common Architecture Patterns

### Pattern 1: Batch Processing (Traditional ETL)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Batch Processing Architecture                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚ Source Systems (OLTP):                                      â”‚
â”‚ â”œâ”€ PostgreSQL (transactions)                               â”‚
â”‚ â”œâ”€ MySQL (user data)                                       â”‚
â”‚ â””â”€ MongoDB (logs)                                          â”‚
â”‚         â”‚                                                   â”‚
â”‚         â–¼                                                   â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚ â”‚ Extract (Nightly)â”‚  (Airflow DAG runs at 2am)           â”‚
â”‚ â”‚ - Full dump      â”‚                                       â”‚
â”‚ â”‚ - Incremental    â”‚                                       â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚          â–¼                                                  â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚ â”‚ Staging (S3/HDFS)â”‚                                       â”‚
â”‚ â”‚ - Raw data       â”‚                                       â”‚
â”‚ â”‚ - Partitioned    â”‚                                       â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚          â–¼                                                  â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚ â”‚ Transform (Spark)â”‚                                       â”‚
â”‚ â”‚ - Clean          â”‚                                       â”‚
â”‚ â”‚ - Join           â”‚                                       â”‚
â”‚ â”‚ - Aggregate      â”‚                                       â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚          â–¼                                                  â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚ â”‚ Load (Warehouse) â”‚                                       â”‚
â”‚ â”‚ - Snowflake      â”‚                                       â”‚
â”‚ â”‚ - BigQuery       â”‚                                       â”‚
â”‚ â”‚ - Redshift       â”‚                                       â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚                                                             â”‚
â”‚ Characteristics:                                            â”‚
â”‚ â”œâ”€ Latency: Hours to days                                  â”‚
â”‚ â”œâ”€ Throughput: High (process TB overnight)                 â”‚
â”‚ â”œâ”€ Complexity: Low (simple pipelines)                      â”‚
â”‚ â””â”€ Cost: Low (batch compute is cheap)                      â”‚
â”‚                                                             â”‚
â”‚ Use Cases:                                                  â”‚
â”‚ â”œâ”€ Daily reports (revenue, KPIs)                           â”‚
â”‚ â”œâ”€ ML training (historical data)                           â”‚
â”‚ â””â”€ Data warehousing (OLAP)                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Pros:**
- Simple to understand and implement
- High throughput (can process TB of data)
- Cost-effective (batch compute is cheap)
- Well-established tools (Airflow, Spark)

**Cons:**
- High latency (hours to days)
- No real-time insights
- Reprocessing is expensive (must rerun entire batch)

---

### Pattern 2: Streaming Processing (Real-Time)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Streaming Architecture                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚ Event Sources:                                              â”‚
â”‚ â”œâ”€ User clicks (website, mobile app)                       â”‚
â”‚ â”œâ”€ IoT sensors (temperature, location)                     â”‚
â”‚ â””â”€ Transaction logs (CDC from databases)                   â”‚
â”‚         â”‚                                                   â”‚
â”‚         â–¼                                                   â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚ â”‚ Message Queue    â”‚                                       â”‚
â”‚ â”‚ - Kafka          â”‚  (Buffering, replay, partitioning)   â”‚
â”‚ â”‚ - Kinesis        â”‚                                       â”‚
â”‚ â”‚ - Pub/Sub        â”‚                                       â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚          â–¼                                                  â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚ â”‚ Stream Processor â”‚                                       â”‚
â”‚ â”‚ - Flink          â”‚  (Windowing, aggregations, joins)    â”‚
â”‚ â”‚ - Spark Streamingâ”‚                                       â”‚
â”‚ â”‚ - Beam/Dataflow  â”‚                                       â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚          â–¼                                                  â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚ â”‚ Sinks (Multiple):                â”‚                       â”‚
â”‚ â”‚ â”œâ”€ Real-time DB (DynamoDB, Bigtable)                    â”‚
â”‚ â”‚ â”œâ”€ Search (Elasticsearch)                               â”‚
â”‚ â”‚ â”œâ”€ Cache (Redis)                                        â”‚
â”‚ â”‚ â””â”€ Data Lake (S3, for batch)                            â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                                                             â”‚
â”‚ Characteristics:                                            â”‚
â”‚ â”œâ”€ Latency: Milliseconds to seconds                        â”‚
â”‚ â”œâ”€ Throughput: Medium (1M events/sec)                      â”‚
â”‚ â”œâ”€ Complexity: High (state management, exactly-once)       â”‚
â”‚ â””â”€ Cost: High (always-on compute)                          â”‚
â”‚                                                             â”‚
â”‚ Use Cases:                                                  â”‚
â”‚ â”œâ”€ Fraud detection (real-time alerts)                      â”‚
â”‚ â”œâ”€ Recommendation engines (personalized content)           â”‚
â”‚ â”œâ”€ Real-time dashboards (metrics, monitoring)              â”‚
â”‚ â””â”€ Operational analytics (live KPIs)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Pros:**
- Low latency (sub-second)
- Real-time insights
- Incremental processing (no reprocessing)

**Cons:**
- Complex (state management, exactly-once semantics)
- Expensive (always-on compute)
- Harder to debug (distributed, stateful)

---

### Pattern 3: Lambda Architecture (Batch + Streaming)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Lambda Architecture                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚                     â”‚ Data Sources â”‚                        â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                             â”‚                               â”‚
â”‚                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚                â–¼                         â–¼                  â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚    â”‚ Batch Layer (Spark) â”‚   â”‚ Speed Layer (Flink) â”‚       â”‚
â”‚    â”‚ - Full history      â”‚   â”‚ - Recent data only  â”‚       â”‚
â”‚    â”‚ - High latency      â”‚   â”‚ - Low latency       â”‚       â”‚
â”‚    â”‚ - Accurate          â”‚   â”‚ - Approximate       â”‚       â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚               â”‚                         â”‚                   â”‚
â”‚               â–¼                         â–¼                   â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚    â”‚ Batch Views         â”‚   â”‚ Real-time Views     â”‚       â”‚
â”‚    â”‚ (Data Warehouse)    â”‚   â”‚ (Redis, DynamoDB)   â”‚       â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚               â”‚                         â”‚                   â”‚
â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                            â–¼                                â”‚
â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚                  â”‚ Serving Layer     â”‚                      â”‚
â”‚                  â”‚ - Merge views     â”‚                      â”‚
â”‚                  â”‚ - Query API       â”‚                      â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                                                             â”‚
â”‚ Query Logic:                                                â”‚
â”‚ result = batch_view(0 to T-1) + speed_view(T to now)       â”‚
â”‚                                                             â”‚
â”‚ Characteristics:                                            â”‚
â”‚ â”œâ”€ Latency: Low (via speed layer)                          â”‚
â”‚ â”œâ”€ Accuracy: High (via batch layer)                        â”‚
â”‚ â”œâ”€ Complexity: Very high (maintain 2 pipelines)            â”‚
â”‚ â””â”€ Cost: High (run batch + streaming)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Pros:**
- Best of both worlds (low latency + high accuracy)
- Fault-tolerant (batch layer can recompute)

**Cons:**
- Complex (maintain 2 codebases)
- Expensive (run both batch and streaming)
- Hard to keep in sync (eventual consistency)

---

### Pattern 4: Kappa Architecture (Streaming-Only)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Kappa Architecture (Simplified Lambda)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚
â”‚           â”‚ Data Sources â”‚                                  â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                  â”‚
â”‚                   â–¼                                         â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚
â”‚           â”‚ Kafka (Log)  â”‚  (Immutable, replayable)        â”‚
â”‚           â”‚ - Infinite   â”‚                                  â”‚
â”‚           â”‚   retention  â”‚                                  â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                  â”‚
â”‚                   â–¼                                         â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚
â”‚           â”‚ Stream       â”‚                                  â”‚
â”‚           â”‚ Processor    â”‚  (Flink, Spark, Beam)           â”‚
â”‚           â”‚ - Stateful   â”‚                                  â”‚
â”‚           â”‚ - Exactly-   â”‚                                  â”‚
â”‚           â”‚   once       â”‚                                  â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                  â”‚
â”‚                   â–¼                                         â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚
â”‚           â”‚ Materialized â”‚                                  â”‚
â”‚           â”‚ Views        â”‚  (Real-time + historical)       â”‚
â”‚           â”‚ - Redis      â”‚                                  â”‚
â”‚           â”‚ - Cassandra  â”‚                                  â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚
â”‚                                                             â”‚
â”‚ Reprocessing (no batch layer):                             â”‚
â”‚ 1. Deploy new streaming job (version 2)                    â”‚
â”‚ 2. Replay Kafka from offset 0                              â”‚
â”‚ 3. Build new materialized views                            â”‚
â”‚ 4. Switch traffic to new views                             â”‚
â”‚                                                             â”‚
â”‚ Characteristics:                                            â”‚
â”‚ â”œâ”€ Latency: Low (streaming-only)                           â”‚
â”‚ â”œâ”€ Complexity: Medium (1 codebase)                         â”‚
â”‚ â”œâ”€ Cost: Medium (streaming compute)                        â”‚
â”‚ â””â”€ Reprocessing: Replay from Kafka                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Pros:**
- Simpler than Lambda (1 codebase)
- Low latency
- Easy to reprocess (replay Kafka)

**Cons:**
- Requires infinite retention (Kafka storage cost)
- Streaming framework must be powerful (Flink, Beam)
- Hard to debug historical issues

---

## ðŸš« 3. Anti-Patterns

### Anti-Pattern 1: The "Big Ball of Mud"

```
Problem: Monolithic pipeline with no modularity

Bad:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ single_giant_pipeline.py (5000 lines)                   â”‚
â”‚ â”œâ”€ Extract from 10 sources                             â”‚
â”‚ â”œâ”€ Transform with 50 steps                             â”‚
â”‚ â”œâ”€ Load to 5 destinations                              â”‚
â”‚ â””â”€ No separation of concerns                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Consequences:
â”œâ”€ âŒ Hard to test (must test entire pipeline)
â”œâ”€ âŒ Hard to debug (which step failed?)
â”œâ”€ âŒ Hard to scale (can't parallelize)
â””â”€ âŒ Hard to modify (change 1 line, risk breaking everything)

Good:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Modular Pipeline (Airflow DAG)                          â”‚
â”‚ â”œâ”€ extract_postgres (task 1)                           â”‚
â”‚ â”œâ”€ extract_api (task 2, parallel with task 1)          â”‚
â”‚ â”œâ”€ transform_clean (task 3, depends on 1+2)            â”‚
â”‚ â”œâ”€ transform_aggregate (task 4, depends on 3)          â”‚
â”‚ â””â”€ load_warehouse (task 5, depends on 4)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Benefits:
â”œâ”€ âœ… Each task is testable
â”œâ”€ âœ… Easy to debug (view logs per task)
â”œâ”€ âœ… Parallelizable (tasks 1+2 run together)
â””â”€ âœ… Modifiable (change 1 task without risk)
```

---

### Anti-Pattern 2: No Idempotency

```
Problem: Re-running pipeline creates duplicates

Bad:
def load_data():
    data = extract()
    for record in data:
        db.execute("INSERT INTO users VALUES (%s, %s)", record)
    # Re-run â†’ Duplicates! âŒ

Consequences:
â”œâ”€ âŒ Duplicates in database
â”œâ”€ âŒ Cannot retry on failure
â””â”€ âŒ Data reconciliation issues

Good (Idempotent):
def load_data():
    data = extract()
    for record in data:
        db.execute("""
            INSERT INTO users (id, name)
            VALUES (%s, %s)
            ON CONFLICT (id) DO UPDATE SET name = EXCLUDED.name
        """, record)
    # Re-run â†’ No duplicates! âœ…

Or use staging table:
def load_data():
    data = extract()
    
    # Truncate staging
    db.execute("TRUNCATE TABLE users_staging")
    
    # Load to staging
    for record in data:
        db.execute("INSERT INTO users_staging VALUES (%s, %s)", record)
    
    # Atomic swap
    db.execute("BEGIN")
    db.execute("DROP TABLE users_old")
    db.execute("ALTER TABLE users RENAME TO users_old")
    db.execute("ALTER TABLE users_staging RENAME TO users")
    db.execute("COMMIT")
```

---

### Anti-Pattern 3: No Monitoring (Flying Blind)

```
Problem: Pipeline runs silently, failures go unnoticed

Bad:
try:
    run_pipeline()
except Exception as e:
    print(f"Error: {e}")  # Lost in logs âŒ

Consequences:
â”œâ”€ âŒ Data staleness goes undetected
â”œâ”€ âŒ Failures discovered by users (embarrassing)
â””â”€ âŒ No historical metrics (can't optimize)

Good:
import logging
import statsd
from datetime import datetime

logger = logging.getLogger(__name__)
metrics = statsd.StatsClient('statsd-server', 8125)

def run_pipeline():
    start_time = datetime.now()
    
    try:
        # Extract
        logger.info("Starting extraction")
        records = extract()
        metrics.gauge('pipeline.records.extracted', len(records))
        
        # Transform
        logger.info("Starting transformation")
        transformed = transform(records)
        metrics.gauge('pipeline.records.transformed', len(transformed))
        
        # Load
        logger.info("Starting load")
        load(transformed)
        metrics.gauge('pipeline.records.loaded', len(transformed))
        
        # Success metrics
        duration = (datetime.now() - start_time).total_seconds()
        metrics.timing('pipeline.duration', duration)
        metrics.increment('pipeline.success')
        
        logger.info(f"Pipeline succeeded in {duration}s")
        send_slack_notification("âœ… Pipeline success", color="good")
        
    except Exception as e:
        logger.error(f"Pipeline failed: {e}", exc_info=True)
        metrics.increment('pipeline.failure')
        send_pagerduty_alert(f"Pipeline failed: {e}")
        send_slack_notification(f"âŒ Pipeline failed: {e}", color="danger")
        raise
```

---

### Anti-Pattern 4: Hardcoded Configuration

```
Problem: Config baked into code

Bad:
def extract():
    conn = psycopg2.connect(
        host="prod-db.company.com",  # Hardcoded! âŒ
        user="admin",
        password="P@ssw0rd123",  # Password in code! âŒâŒâŒ
        database="production"
    )

Consequences:
â”œâ”€ âŒ Cannot test in dev (different DB)
â”œâ”€ âŒ Security risk (password in version control)
â””â”€ âŒ Hard to change (must redeploy code)

Good:
import os
from dataclasses import dataclass

@dataclass
class Config:
    db_host: str
    db_user: str
    db_password: str
    db_name: str
    
    @classmethod
    def from_env(cls):
        return cls(
            db_host=os.environ['DB_HOST'],
            db_user=os.environ['DB_USER'],
            db_password=os.environ['DB_PASSWORD'],  # From secrets manager
            db_name=os.environ['DB_NAME'],
        )

config = Config.from_env()

def extract():
    conn = psycopg2.connect(
        host=config.db_host,
        user=config.db_user,
        password=config.db_password,
        database=config.db_name,
    )

# Deployment:
# dev:  DB_HOST=dev-db.company.com
# prod: DB_HOST=prod-db.company.com
```

---

## ðŸ“Š 4. Monitoring Fundamentals

### The Three Pillars of Observability

```
1. Logging:
   â”œâ”€ What: Discrete events (errors, warnings, info)
   â”œâ”€ Format: Structured JSON logs
   â”œâ”€ Storage: Elasticsearch, Splunk, CloudWatch
   â””â”€ Query: "Show me all errors in last hour"

2. Metrics:
   â”œâ”€ What: Numerical time-series data
   â”œâ”€ Types: Counters, gauges, histograms
   â”œâ”€ Storage: Prometheus, InfluxDB, Datadog
   â””â”€ Query: "What's the P95 latency?"

3. Tracing:
   â”œâ”€ What: Request flow through distributed system
   â”œâ”€ Format: Spans (operation duration) + trace ID
   â”œâ”€ Storage: Jaeger, Zipkin, X-Ray
   â””â”€ Query: "Why is this request slow?"
```

---

### Key Metrics to Track

```python
# Throughput metrics
metrics.gauge('pipeline.records.per_second', records_per_sec)
metrics.gauge('pipeline.bytes.per_second', bytes_per_sec)

# Latency metrics
metrics.histogram('pipeline.task.duration', task_duration)
metrics.histogram('pipeline.end_to_end.duration', total_duration)

# Error metrics
metrics.increment('pipeline.errors.total')
metrics.increment('pipeline.errors.retryable')
metrics.increment('pipeline.errors.fatal')

# Data quality metrics
metrics.gauge('data.null_percentage', null_count / total_count * 100)
metrics.gauge('data.duplicate_percentage', dup_count / total_count * 100)

# Resource metrics
metrics.gauge('pipeline.cpu.usage_percent', cpu_usage)
metrics.gauge('pipeline.memory.usage_mb', memory_mb)
metrics.gauge('pipeline.disk.usage_gb', disk_gb)

# SLA metrics
metrics.gauge('pipeline.freshness.minutes', freshness_minutes)
metrics.gauge('pipeline.completeness.percent', completeness_pct)
```

---

## ðŸš¨ 5. Alerting Strategies

### Alert Fatigue Prevention

```
Bad Alerting:
â”œâ”€ Alert on every error (100 alerts/day) âŒ
â”œâ”€ No prioritization (all alerts are "critical") âŒ
â””â”€ No context (alert says "Error" with no details) âŒ

Result: Team ignores alerts, real issues missed

Good Alerting:
â”œâ”€ Alert only on SLA violations âœ…
â”œâ”€ Prioritize: P0 (page), P1 (email), P2 (ticket) âœ…
â””â”€ Include context (error message, runbook link) âœ…
```

---

### Severity Levels

```
P0 (Critical - Page on-call):
â”œâ”€ Pipeline down >15 minutes
â”œâ”€ Data corruption detected
â”œâ”€ Security breach
â””â”€ Customer-facing impact

P1 (High - Email + Slack):
â”œâ”€ Pipeline delay >1 hour
â”œâ”€ Data quality check failed
â”œâ”€ Elevated error rate (>5%)
â””â”€ Resource exhaustion (disk 90% full)

P2 (Medium - Ticket):
â”œâ”€ Pipeline delay <1 hour
â”œâ”€ Single task failure (auto-retry working)
â”œâ”€ Warning-level issues
â””â”€ Performance degradation (P95 latency up 20%)

P3 (Low - Log only):
â”œâ”€ Informational events
â”œâ”€ Successful completions
â””â”€ Routine maintenance
```

---

### Example Alert Rules

```yaml
# Prometheus alert rules

groups:
  - name: data_pipeline
    interval: 1m
    rules:
      # P0: Pipeline down
      - alert: PipelineDown
        expr: time() - pipeline_last_success_timestamp > 900  # 15 min
        labels:
          severity: critical
        annotations:
          summary: "Pipeline {{ $labels.pipeline_name }} down for 15+ minutes"
          description: "Last success: {{ $value }}s ago"
          runbook: "https://wiki.company.com/runbooks/pipeline-down"
      
      # P1: High error rate
      - alert: HighErrorRate
        expr: rate(pipeline_errors_total[5m]) > 0.05  # 5% error rate
        labels:
          severity: high
        annotations:
          summary: "Pipeline {{ $labels.pipeline_name }} error rate >5%"
          description: "Current rate: {{ $value | humanizePercentage }}"
      
      # P1: Data freshness SLA violated
      - alert: DataStale
        expr: pipeline_freshness_minutes > 60  # Data >1 hour old
        labels:
          severity: high
        annotations:
          summary: "Data in {{ $labels.table_name }} is stale"
          description: "Freshness: {{ $value }} minutes (SLA: 60 minutes)"
      
      # P2: Disk usage high
      - alert: DiskUsageHigh
        expr: pipeline_disk_usage_percent > 90
        labels:
          severity: medium
        annotations:
          summary: "Disk usage >90% on {{ $labels.instance }}"
          description: "Usage: {{ $value }}%"
```

---

## ðŸ“š Summary Checklist

- [ ] Understand production vs development differences
- [ ] Identify common architecture patterns (batch, streaming, Lambda, Kappa)
- [ ] Recognize anti-patterns (big ball of mud, no idempotency, no monitoring, hardcoded config)
- [ ] Implement the three pillars of observability (logging, metrics, tracing)
- [ ] Design effective alerting (avoid alert fatigue, prioritize by severity)
- [ ] Track key metrics (throughput, latency, errors, data quality, SLA)
- [ ] Build production-ready systems (fault-tolerant, monitored, documented)

**Next:** [INTERMEDIATE.md â†’](INTERMEDIATE.md)
