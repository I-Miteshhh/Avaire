# Week 8-9: Apache Flink â€” EXPERT Track

*"Flink's Chandy-Lamport implementation with barrier alignment achieves exactly-once semantics without sacrificing throughput. Understanding savepoints, RocksDB internals, and CEP is what separates good engineers from architects."* â€” Data Platform Architect, Uber

---

## ğŸ¯ Learning Outcomes

By the end of this track, you will:
- Master Chandy-Lamport distributed snapshot algorithm
- Understand exactly-once semantics end-to-end (source, processing, sink)
- Optimize RocksDB state backend for production workloads
- Implement Complex Event Processing (CEP) patterns
- Handle backpressure and resource management
- Design multi-tenant Flink deployments
- Troubleshoot production incidents (checkpoint failures, OOM, backpressure)

---

## ğŸ”¬ 1. Chandy-Lamport Distributed Snapshots

### The Problem: Consistent Global State

```
Challenge: Snapshot state of distributed system without stopping execution

Example: Bank transfers
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Account A: $1000                Account B: $500            â”‚
â”‚                                                            â”‚
â”‚ Transfer $200 from A to B:                                 â”‚
â”‚ â”œâ”€ T1: A = $1000 - $200 = $800                            â”‚
â”‚ â””â”€ T2: B = $500 + $200 = $700                             â”‚
â”‚                                                            â”‚
â”‚ Snapshot taken BETWEEN T1 and T2:                         â”‚
â”‚ â”œâ”€ A = $800 (after debit)                                â”‚
â”‚ â”œâ”€ B = $500 (before credit)                              â”‚
â”‚ â””â”€ Total = $1300 âŒ INCONSISTENT! ($200 lost in flight)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Chandy-Lamport Solution:
- Snapshot local state
- Snapshot in-flight messages (data in network buffers)
- Reconstruct consistent global state
```

---

### Chandy-Lamport Algorithm (Original)

```
Distributed System with 3 processes:

Process P1 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> Process P2
                    â”‚
                    â”‚ messages
                    â–¼
              Process P3

Algorithm:
1. Initiator (P1) snapshots its local state
2. P1 sends MARKER message on all outgoing channels
3. P1 starts recording incoming messages

When process receives MARKER:
â”œâ”€ If first MARKER on any channel:
â”‚  â”œâ”€ Snapshot local state
â”‚  â”œâ”€ Send MARKER on all outgoing channels
â”‚  â””â”€ Start recording messages on OTHER channels
â””â”€ If already snapshotted:
   â””â”€ Stop recording on this channel

Termination: All processes snapshotted + all channel states recorded
```

**Example Execution:**

```
Time T0: P1 initiates snapshot
â”œâ”€ P1: state = {x=10}, sends MARKER to P2, P3

Time T1: P2 receives MARKER from P1
â”œâ”€ P2: snapshot state = {y=20}
â”œâ”€ P2: sends MARKER to P1, P3
â”œâ”€ P2: records channel P3â†’P2

Time T2: P3 receives MARKER from P1
â”œâ”€ P3: snapshot state = {z=30}
â”œâ”€ P3: sends MARKER to P1, P2
â”œâ”€ P3: stops recording P1â†’P3 (already received MARKER)

Time T3: All markers received
â”œâ”€ Global snapshot: P1={x=10}, P2={y=20}, P3={z=30}
â”œâ”€ Channel states: P1â†’P2=[msg1], P3â†’P2=[msg2], ...
```

---

### Flink's Barrier-Based Implementation

```
Flink Adaptation:
- MARKER â†’ CHECKPOINT BARRIER
- Channels â†’ Flink data streams
- Process state â†’ Operator state

Checkpoint Barrier Flow:

Source 1:  [e1] [e2] â”€â”€BARRIER(ckpt-5)â”€â”€ [e3] [e4] [e5]
Source 2:  [e6] [e7] â”€â”€BARRIER(ckpt-5)â”€â”€ [e8] [e9] [e10]
                    â”‚
                    â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  Stateful Op 1   â”‚  (2 input channels)
            â”‚ (keyBy + window) â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
            Barrier Alignment:
            â”œâ”€ Receive barrier from Source 1 at time T1
            â”œâ”€ Block Source 1, buffer events [e3, e4, e5]
            â”œâ”€ Continue processing Source 2
            â”œâ”€ Receive barrier from Source 2 at time T2
            â””â”€ Both barriers aligned! Snapshot state.
                    â”‚
                    â–¼
            State Snapshot:
            â”œâ”€ Keyed state: {user_id=123 â†’ count=5, ...}
            â”œâ”€ Window buffers: [e1, e2, e6, e7]
            â”œâ”€ In-flight events: [e3, e4, e5] (buffered)
            â””â”€ Acknowledge to JobManager
```

---

### Barrier Alignment vs Unaligned Checkpoints

```java
// ALIGNED (Default): Wait for all barriers
config.enableUnalignedCheckpoints(false);

Aligned Checkpoint Timeline:
T=0:    Barrier arrives at input 1
T=0-50: Buffer events from input 1, process input 2
T=50:   Barrier arrives at input 2
T=50:   SNAPSHOT state (includes buffered events)
T=51:   Continue processing

Cost: 50ms latency increase (barrier alignment)
Benefit: Smaller checkpoint size

// UNALIGNED: Don't wait, snapshot buffers
config.enableUnalignedCheckpoints(true);

Unaligned Checkpoint Timeline:
T=0:    Barrier arrives at input 1
T=0:    SNAPSHOT state + in-flight buffers IMMEDIATELY
T=1:    Continue processing (no blocking)
T=50:   Barrier arrives at input 2 (ignored)

Cost: Larger checkpoint (includes in-flight data)
Benefit: No latency increase, handles backpressure better
```

**Unaligned Checkpoint Deep Dive:**

```
Unaligned checkpoint includes:

1. Operator State:
   â”œâ”€ Keyed state: HashMap<Key, Value>
   â””â”€ Operator state: ListState, BroadcastState

2. In-Flight Buffers (NEW):
   â”œâ”€ Input buffers: Events received but not processed
   â”œâ”€ Output buffers: Events processed but not sent
   â””â”€ Network buffers: Events in network stack

Example:
Input buffer:  [e3, e4, e5] (waiting to be processed)
Output buffer: [e10, e11] (waiting to be sent)

Checkpoint includes ALL:
â”œâ”€ State: {user_id=123 â†’ count=5}
â”œâ”€ Input buffer: [e3, e4, e5]
â””â”€ Output buffer: [e10, e11]

On recovery:
â”œâ”€ Restore state
â”œâ”€ Replay input buffer events
â””â”€ Resend output buffer events
```

**When to use unaligned:**

```
Use aligned checkpoints when:
â”œâ”€ Low backpressure (barriers aligned quickly)
â”œâ”€ Small in-flight data
â””â”€ Checkpoint storage is expensive

Use unaligned checkpoints when:
â”œâ”€ High backpressure (barrier alignment takes >1 second)
â”œâ”€ Large in-flight data is acceptable
â””â”€ Checkpoint latency is critical
```

---

## ğŸ¯ 2. Exactly-Once Semantics End-to-End

### Three Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Source    â”‚ â”€â”€â”€> â”‚ Processing  â”‚ â”€â”€â”€> â”‚    Sink     â”‚
â”‚ (Kafka)     â”‚      â”‚  (Flink)    â”‚      â”‚  (Kafka)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                     â”‚                     â”‚
      â–¼                     â–¼                     â–¼
Exactly-once         Exactly-once         Exactly-once
source reads         processing           sink writes

Requirements:
1. Replayable source (Kafka offsets)
2. Checkpointed processing (Flink barriers)
3. Transactional sink (2PC commit)
```

---

### Source: Kafka Offset Management

```java
FlinkKafkaConsumer<String> consumer = new FlinkKafkaConsumer<>(
    "events",
    new SimpleStringSchema(),
    properties
);

// Enable offset checkpointing
consumer.setCommitOffsetsOnCheckpoints(true);

// Checkpoint includes Kafka offsets:
Checkpoint State:
â”œâ”€ Operator state: {...}
â”œâ”€ Kafka offsets: {
â”‚    partition-0: offset=12345,
â”‚    partition-1: offset=67890,
â”‚    partition-2: offset=11111
â”‚  }
```

**Recovery Process:**

```
Job fails at T=100:
â”œâ”€ Last successful checkpoint: T=80 (ckpt-5)
â”œâ”€ Kafka offsets at ckpt-5:
â”‚  â”œâ”€ partition-0: offset=10000
â”‚  â”œâ”€ partition-1: offset=50000
â”‚  â””â”€ partition-2: offset=9000

Recovery:
1. Restore operator state from ckpt-5
2. Seek Kafka consumers to checkpointed offsets:
   â”œâ”€ consumer-0.seek(partition-0, 10000)
   â”œâ”€ consumer-1.seek(partition-1, 50000)
   â””â”€ consumer-2.seek(partition-2, 9000)
3. Resume processing from offset 10000, 50000, 9000

Result: Events from T=80 to T=100 are REPLAYED (exactly-once)
```

---

### Sink: Two-Phase Commit (2PC)

```
Transactional Sink (Kafka, JDBC, etc.):

Phase 1: Pre-commit (during checkpoint)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Checkpoint barrier arrives at sink                   â”‚
â”‚ â”œâ”€ Flush buffered records to transaction            â”‚
â”‚ â”œâ”€ Kafka: kafkaProducer.flush()                     â”‚
â”‚ â”œâ”€ Do NOT commit yet!                               â”‚
â”‚ â””â”€ Acknowledge checkpoint to JobManager             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Phase 2: Commit (after checkpoint completes)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ JobManager confirms checkpoint success               â”‚
â”‚ â”œâ”€ Notify all sinks: "Checkpoint X completed"       â”‚
â”‚ â”œâ”€ Sinks commit transactions:                       â”‚
â”‚ â”‚  â”œâ”€ Kafka: kafkaProducer.commitTransaction()     â”‚
â”‚ â”‚  â””â”€ JDBC: connection.commit()                    â”‚
â”‚ â””â”€ Records become visible to consumers              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Failure Handling:
- If checkpoint fails â†’ Abort transactions
- If sink fails after pre-commit â†’ Restore from checkpoint, retry
```

**Kafka Transactional Producer:**

```java
import org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer;
import org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer.Semantic;

Properties props = new Properties();
props.setProperty("bootstrap.servers", "localhost:9092");
props.setProperty("transaction.timeout.ms", "900000");  // 15 min

FlinkKafkaProducer<String> producer = new FlinkKafkaProducer<>(
    "output-topic",
    new SimpleStringSchema(),
    props,
    Semantic.EXACTLY_ONCE  // Enable transactions
);

stream.addSink(producer);
```

**2PC Protocol Deep Dive:**

```
Timeline:

T=0:  Checkpoint 5 starts
      â”œâ”€ Sink receives barrier
      â”œâ”€ kafkaProducer.beginTransaction("txn-5")
      â”œâ”€ Buffered records: [r1, r2, r3]
      â”œâ”€ kafkaProducer.send(r1, r2, r3)  (to transaction)
      â””â”€ kafkaProducer.flush()  (ensure sent)

T=10: Sink acknowledges checkpoint 5
      â”œâ”€ Transaction "txn-5" in PREPARED state
      â””â”€ Wait for JobManager confirmation

T=20: JobManager confirms checkpoint 5 success
      â”œâ”€ Notify sink: "Commit txn-5"
      â””â”€ kafkaProducer.commitTransaction("txn-5")

T=21: Records [r1, r2, r3] become visible to consumers

Failure Scenario:
T=15: Job fails BEFORE commit
      â”œâ”€ Transaction "txn-5" in PREPARED state
      â”œâ”€ Kafka times out transaction (transaction.timeout.ms)
      â””â”€ Transaction ABORTED, records NOT visible

Recovery:
â”œâ”€ Restore from checkpoint 4
â”œâ”€ Replay records [r1, r2, r3]
â””â”€ New transaction "txn-6" commits successfully
```

---

## ğŸ—„ï¸ 3. RocksDB State Backend Internals

### LSM-Tree Architecture

```
RocksDB = Log-Structured Merge-Tree

Write Path:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Write to WAL (Write-Ahead Log)                       â”‚
â”‚    â””â”€ Durability: Crash recovery                        â”‚
â”‚ 2. Insert into MemTable (in-memory sorted map)          â”‚
â”‚    â””â”€ Fast writes: O(log N) insert                      â”‚
â”‚ 3. When MemTable full â†’ Flush to SST file (Level 0)     â”‚
â”‚    â””â”€ Immutable SSTable (sorted string table)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Read Path:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Check MemTable (newest data)                         â”‚
â”‚ 2. Check Block Cache (in-memory LRU cache)              â”‚
â”‚ 3. Check Bloom Filters (avoid disk reads)               â”‚
â”‚ 4. Read SST files (Level 0 â†’ Level 1 â†’ ... â†’ Level 6)   â”‚
â”‚    â””â”€ Binary search within SST file                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Compaction:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Background process merges SST files:                    â”‚
â”‚ Level 0: [sst-1, sst-2, sst-3, sst-4]  (overlapping)   â”‚
â”‚    â†“ Compact                                            â”‚
â”‚ Level 1: [sst-5, sst-6]  (non-overlapping)              â”‚
â”‚    â†“ Compact                                            â”‚
â”‚ Level 2: [sst-7]                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### RocksDB Configuration for Flink

```java
import org.apache.flink.contrib.streaming.state.EmbeddedRocksDBStateBackend;
import org.apache.flink.contrib.streaming.state.RocksDBOptionsFactory;
import org.rocksdb.*;

public class CustomRocksDBConfig implements RocksDBOptionsFactory {
    
    @Override
    public DBOptions createDBOptions(DBOptions currentOptions, Collection<AutoCloseable> handlesToClose) {
        return currentOptions
            // Parallelism for background jobs (compaction, flush)
            .setMaxBackgroundJobs(4)
            
            // Limit open files (avoid "too many open files" error)
            .setMaxOpenFiles(1000)
            
            // WAL configuration
            .setMaxTotalWalSize(256 * 1024 * 1024)  // 256 MB
            
            // Statistics (for debugging)
            .setStatistics(new Statistics())
            .setStatsDumpPeriodSec(60);
    }
    
    @Override
    public ColumnFamilyOptions createColumnOptions(ColumnFamilyOptions currentOptions, Collection<AutoCloseable> handlesToClose) {
        return currentOptions
            // Write buffer size (MemTable size)
            .setWriteBufferSize(64 * 1024 * 1024)  // 64 MB
            
            // Number of write buffers (allows parallel flushes)
            .setMaxWriteBufferNumber(3)
            
            // Trigger compaction when 4 Level-0 files exist
            .setLevel0FileNumCompactionTrigger(4)
            
            // Block size for SST files (trade-off: read amplification vs memory)
            .setBlockSize(16 * 1024)  // 16 KB
            
            // Compression (zstd has best ratio, but slower)
            .setCompressionType(CompressionType.SNAPPY_COMPRESSION)
            .setBottommostCompressionType(CompressionType.ZSTD_COMPRESSION)
            
            // Bloom filter (reduces disk reads)
            .setTableFormatConfig(
                new BlockBasedTableConfig()
                    .setFilterPolicy(new BloomFilter(10, false))
                    .setBlockCache(new LRUCache(256 * 1024 * 1024))  // 256 MB
            )
            
            // Compaction style (LEVEL for read-heavy, UNIVERSAL for write-heavy)
            .setCompactionStyle(CompactionStyle.LEVEL);
    }
}

// Apply configuration:
EmbeddedRocksDBStateBackend rocksDB = new EmbeddedRocksDBStateBackend();
rocksDB.setRocksDBOptions(new CustomRocksDBConfig());
env.setStateBackend(rocksDB);
```

---

### Tuning for Different Workloads

```
Read-Heavy Workload (high get() calls):
â”œâ”€ Increase block cache size: 512 MB - 2 GB
â”œâ”€ Enable bloom filters: BloomFilter(10)
â”œâ”€ Use LEVEL compaction
â””â”€ Smaller write buffers: 32 MB

rocksDB.setRocksDBOptions(new RocksDBOptionsFactory() {
    @Override
    public ColumnFamilyOptions createColumnOptions(...) {
        return currentOptions
            .setWriteBufferSize(32 * 1024 * 1024)
            .setTableFormatConfig(
                new BlockBasedTableConfig()
                    .setBlockCache(new LRUCache(2L * 1024 * 1024 * 1024))  // 2 GB
                    .setFilterPolicy(new BloomFilter(10, false))
            );
    }
});

Write-Heavy Workload (high put() calls):
â”œâ”€ Increase write buffer size: 128 MB
â”œâ”€ More write buffers: 4-6
â”œâ”€ Use UNIVERSAL compaction
â””â”€ Reduce block cache: 128 MB

rocksDB.setRocksDBOptions(new RocksDBOptionsFactory() {
    @Override
    public ColumnFamilyOptions createColumnOptions(...) {
        return currentOptions
            .setWriteBufferSize(128 * 1024 * 1024)
            .setMaxWriteBufferNumber(6)
            .setCompactionStyle(CompactionStyle.UNIVERSAL)
            .setTableFormatConfig(
                new BlockBasedTableConfig()
                    .setBlockCache(new LRUCache(128 * 1024 * 1024))
            );
    }
});

Large State (>100 GB per operator):
â”œâ”€ Enable incremental checkpoints
â”œâ”€ Increase max_open_files: 5000
â”œâ”€ Use tiered storage (SSD for hot, HDD for cold)
â””â”€ Monitor compaction lag

rocksDB.enableIncrementalCheckpointing(true);
rocksDB.setRocksDBOptions(new RocksDBOptionsFactory() {
    @Override
    public DBOptions createDBOptions(...) {
        return currentOptions
            .setMaxOpenFiles(5000)
            .setMaxBackgroundJobs(8);
    }
});
```

---

### Incremental Checkpointing

```
Full Checkpoint (default):
â”œâ”€ Checkpoint 1: Upload ALL SST files (10 GB)
â”œâ”€ Checkpoint 2: Upload ALL SST files (12 GB)
â””â”€ Checkpoint 3: Upload ALL SST files (15 GB)

Total uploaded: 37 GB
Checkpoint time: ~5 minutes per checkpoint

Incremental Checkpoint:
â”œâ”€ Checkpoint 1: Upload ALL SST files (10 GB)
â”œâ”€ Checkpoint 2: Upload ONLY new/modified SST files (2 GB)
â””â”€ Checkpoint 3: Upload ONLY new/modified SST files (3 GB)

Total uploaded: 15 GB
Checkpoint time: ~30 seconds per checkpoint

Implementation:
rocksDB.enableIncrementalCheckpointing(true);

Checkpoint Metadata:
{
  "checkpointId": 5,
  "sharedState": [
    "s3://bucket/shared/sst-001",  // Reused from ckpt-4
    "s3://bucket/shared/sst-002",  // Reused from ckpt-4
  ],
  "privateState": [
    "s3://bucket/ckpt-5/sst-003",  // New in ckpt-5
    "s3://bucket/ckpt-5/sst-004"   // New in ckpt-5
  ]
}
```

---

## ğŸ” 4. Complex Event Processing (CEP)

### Pattern Matching

```java
import org.apache.flink.cep.CEP;
import org.apache.flink.cep.PatternStream;
import org.apache.flink.cep.pattern.Pattern;
import org.apache.flink.cep.pattern.conditions.SimpleCondition;

// Detect: "Login â†’ Purchase within 5 minutes"
Pattern<Event, ?> pattern = Pattern
    .<Event>begin("login")
    .where(new SimpleCondition<Event>() {
        @Override
        public boolean filter(Event event) {
            return event.getType().equals("LOGIN");
        }
    })
    .next("purchase")
    .where(new SimpleCondition<Event>() {
        @Override
        public boolean filter(Event event) {
            return event.getType().equals("PURCHASE");
        }
    })
    .within(Time.minutes(5));  // Time constraint

PatternStream<Event> patternStream = CEP.pattern(
    stream.keyBy(Event::getUserId),
    pattern
);

patternStream.select((Map<String, List<Event>> pattern) -> {
    Event login = pattern.get("login").get(0);
    Event purchase = pattern.get("purchase").get(0);
    return new Alert(login.getUserId(), "Quick purchase detected");
});
```

---

### Fraud Detection Pattern

```java
// Detect: "Multiple small transactions followed by large withdrawal"

Pattern<Transaction, ?> fraudPattern = Pattern
    .<Transaction>begin("smallTransactions")
    .where(new SimpleCondition<Transaction>() {
        @Override
        public boolean filter(Transaction txn) {
            return txn.getAmount() < 100;
        }
    })
    .times(5)  // At least 5 small transactions
    .next("largeWithdrawal")
    .where(new SimpleCondition<Transaction>() {
        @Override
        public boolean filter(Transaction txn) {
            return txn.getAmount() > 5000 && txn.getType().equals("WITHDRAWAL");
        }
    })
    .within(Time.hours(1));

PatternStream<Transaction> fraudStream = CEP.pattern(
    transactions.keyBy(Transaction::getAccountId),
    fraudPattern
);

DataStream<Alert> alerts = fraudStream.select((Map<String, List<Transaction>> pattern) -> {
    List<Transaction> small = pattern.get("smallTransactions");
    Transaction large = pattern.get("largeWithdrawal").get(0);
    
    return new Alert(
        large.getAccountId(),
        String.format("Fraud: %d small txns + $%.2f withdrawal", small.size(), large.getAmount())
    );
});
```

---

### Temporal Patterns

```java
// Detect: "Temperature rising continuously for 10 readings"

Pattern<SensorReading, ?> pattern = Pattern
    .<SensorReading>begin("rising")
    .where(new IterativeCondition<SensorReading>() {
        @Override
        public boolean filter(SensorReading value, Context<SensorReading> ctx) throws Exception {
            // Check if current reading > previous reading
            if (!ctx.getEventsForPattern("rising").iterator().hasNext()) {
                return true;  // First event
            }
            
            SensorReading previous = null;
            for (SensorReading prev : ctx.getEventsForPattern("rising")) {
                previous = prev;
            }
            
            return value.getTemperature() > previous.getTemperature();
        }
    })
    .times(10)  // 10 consecutive rising readings
    .consecutive();  // Must be consecutive (no gaps)

PatternStream<SensorReading> risingTemp = CEP.pattern(
    sensorStream.keyBy(SensorReading::getSensorId),
    pattern
);
```

---

## ğŸ“Š 5. Backpressure Handling

### Backpressure Detection

```
Web UI â†’ Job Graph â†’ Click on operator â†’ Backpressure tab

Status:
â”œâ”€ OK: Backpressure ratio < 10%
â”œâ”€ LOW: 10% - 50%
â”œâ”€ HIGH: 50% - 100%  âš ï¸ BOTTLENECK!

Root Cause Analysis:
1. High backpressure on Map operator?
   â””â”€> CPU-intensive processing â†’ Increase parallelism

2. High backpressure on KeyBy operator?
   â””â”€> Data skew (hot keys) â†’ Repartition or salt keys

3. High backpressure on Sink?
   â””â”€> Slow external system â†’ Increase sink parallelism or batch writes
```

---

### Handling Data Skew

```
Problem:
Key distribution: 
â”œâ”€ user_id=123: 1M events (HOT KEY)
â”œâ”€ user_id=456: 100 events
â””â”€ user_id=789: 50 events

Task allocation:
â”œâ”€ Task 1: Processes user_id=123 (1M events) â† BOTTLENECK
â”œâ”€ Task 2: Processes user_id=456 (100 events)
â””â”€ Task 3: Processes user_id=789 (50 events)

Solution 1: Key Salting
stream
    .map(event -> {
        // Add random suffix to hot keys
        String saltedKey = event.getUserId() + "_" + (event.hashCode() % 10);
        return new Tuple2<>(saltedKey, event);
    })
    .keyBy(tuple -> tuple.f0)
    .window(...)
    .aggregate(...)
    .map(result -> {
        // Remove salt
        String originalKey = result.f0.split("_")[0];
        return new Tuple2<>(originalKey, result.f1);
    })
    .keyBy(tuple -> tuple.f0)
    .sum(1);  // Final aggregation

Solution 2: Two-Stage Aggregation
// Stage 1: Local pre-aggregation
stream
    .keyBy(event -> event.getUserId() + "_" + (event.hashCode() % 100))
    .window(TumblingEventTimeWindows.of(Time.minutes(1)))
    .sum("amount")
    // Stage 2: Global aggregation
    .keyBy(result -> result.getUserId())
    .sum("amount");
```

---

## ğŸš€ 6. Production Case Studies

### Uber: Real-Time Pricing

```
Requirements:
â”œâ”€ Process 100M ride events/day
â”œâ”€ Update surge pricing every 30 seconds
â”œâ”€ 99.9% availability
â””â”€ <500ms latency

Architecture:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Kafka (200 partitions)                                       â”‚
â”‚ â”œâ”€ ride_events: START, END, CANCEL                          â”‚
â”‚ â””â”€ geo_hash: sf_downtown, sf_airport, ...                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Flink Job (parallelism=200)                                 â”‚
â”‚ â”œâ”€ KeyBy: geo_hash                                          â”‚
â”‚ â”œâ”€ Window: Sliding (5 min, slide 30 sec)                    â”‚
â”‚ â”œâ”€ Aggregate: COUNT(rides), AVG(wait_time)                  â”‚
â”‚ â””â”€ ProcessFunction: Calculate surge multiplier              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Redis Cache (geo_hash â†’ surge_multiplier)                   â”‚
â”‚ â””â”€ TTL: 30 seconds                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Configuration:
- TaskManagers: 25 (8 slots each)
- RocksDB state backend (incremental checkpoints)
- Checkpoint interval: 1 minute
- Unaligned checkpoints: Enabled
- State size: ~50 GB (30 days of windowed data)
```

---

### Netflix: Viewing Analytics

```
Requirements:
â”œâ”€ Process 500M viewing events/day
â”œâ”€ Generate recommendations in real-time
â”œâ”€ Join with content metadata (enrichment)
â””â”€ Output to S3 for offline analysis

Architecture:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Kafka: viewing_events                                        â”‚
â”‚ â”œâ”€ user_id, content_id, timestamp, duration                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Flink Job 1: Enrichment (parallelism=128)                   â”‚
â”‚ â”œâ”€ BroadcastStream: Content metadata (10k items)            â”‚
â”‚ â”œâ”€ connect() viewing events with metadata                   â”‚
â”‚ â””â”€ Output: Enriched events                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Flink Job 2: Aggregation (parallelism=256)                  â”‚
â”‚ â”œâ”€ KeyBy: user_id                                           â”‚
â”‚ â”œâ”€ Window: Session (30 min gap)                             â”‚
â”‚ â”œâ”€ Aggregate: Total watch time, genres watched              â”‚
â”‚ â””â”€ Output: User viewing sessions                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â–¼                       â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Kafka: recs  â”‚        â”‚ S3 (Parquet) â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

State Management:
- Broadcast state: 100 MB (content metadata)
- Keyed state: 200 GB (user session buffers)
- Checkpoint interval: 5 minutes
- Incremental checkpoints: Enabled
- S3 checkpoint storage
```

---

## ğŸ† Interview Questions (Expert Level)

1. **Explain Chandy-Lamport algorithm and how Flink implements it with barriers.**
2. **How does Flink achieve exactly-once semantics end-to-end? Explain two-phase commit.**
3. **Compare aligned vs unaligned checkpoints. When would you use each?**
4. **Describe RocksDB LSM-tree architecture. How would you tune it for a read-heavy workload?**
5. **How does incremental checkpointing work in RocksDB state backend?**
6. **Design a fraud detection system using Flink CEP. What patterns would you detect?**
7. **Your Flink job has high backpressure on a KeyBy operator. How would you diagnose and fix it?**
8. **How would you handle data skew in a windowed aggregation?**
9. **Explain the trade-offs between checkpoint interval, state size, and recovery time.**
10. **Design a multi-tenant Flink platform. How would you isolate tenants and allocate resources?**

---

## ğŸ“ Summary Checklist

- [ ] Understand Chandy-Lamport distributed snapshots
- [ ] Implement exactly-once semantics with transactional sinks
- [ ] Configure RocksDB for production workloads
- [ ] Design CEP patterns for complex event detection
- [ ] Diagnose and resolve backpressure issues
- [ ] Handle data skew with salting and two-stage aggregation
- [ ] Optimize checkpoint performance (aligned vs unaligned)
- [ ] Answer expert-level interview questions

**Next:** [WHITEPAPERS.md â†’](WHITEPAPERS.md)
