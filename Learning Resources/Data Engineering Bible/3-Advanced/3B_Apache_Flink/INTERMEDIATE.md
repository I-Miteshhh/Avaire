# Week 8-9: Apache Flink â€” INTERMEDIATE Track

*"Flink's checkpointing mechanism enables exactly-once processing with millisecond latencies. Understanding the JobManager, TaskManager architecture and state backends is critical for production deployments."* â€” Flink Committer

---

## ğŸ¯ Learning Outcomes

By the end of this track, you will:
- Master Flink runtime architecture (JobManager, TaskManagers, slots)
- Understand checkpointing internals and recovery mechanisms
- Configure state backends (Memory, FsStateBackend, RocksDB)
- Implement custom operators and ProcessFunctions
- Optimize Flink jobs for throughput and latency
- Design fault-tolerant streaming pipelines

---

## ğŸ—ï¸ 1. Flink Runtime Architecture

### Component Hierarchy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Client (Job Submission)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          JobManager                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ JobGraph      â”‚  â”‚ Scheduler    â”‚  â”‚ Checkpoint       â”‚     â”‚
â”‚  â”‚ (DAG of tasks)â”‚  â”‚              â”‚  â”‚ Coordinator      â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â–¼               â–¼               â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ TaskManager  â”‚ â”‚ TaskManager  â”‚ â”‚ TaskManager  â”‚
        â”‚              â”‚ â”‚              â”‚ â”‚              â”‚
        â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
        â”‚ â”‚  Slot 1  â”‚ â”‚ â”‚ â”‚  Slot 1  â”‚ â”‚ â”‚ â”‚  Slot 1  â”‚ â”‚
        â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚ â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚ â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
        â”‚ â”‚  Slot 2  â”‚ â”‚ â”‚ â”‚  Slot 2  â”‚ â”‚ â”‚ â”‚  Slot 2  â”‚ â”‚
        â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### JobManager Responsibilities

```
1. Job Submission & Planning:
   â”œâ”€ Receive JobGraph from client
   â”œâ”€ Convert JobGraph â†’ ExecutionGraph
   â”œâ”€ Schedule tasks to TaskManagers
   â””â”€ Track task execution status

2. Checkpoint Coordination:
   â”œâ”€ Trigger periodic checkpoints
   â”œâ”€ Collect checkpoint acknowledgments
   â”œâ”€ Store checkpoint metadata
   â””â”€ Orchestrate recovery on failure

3. Resource Management:
   â”œâ”€ Allocate slots from TaskManagers
   â”œâ”€ Handle slot sharing and co-location
   â””â”€ Rescale jobs (dynamic scaling)

4. High Availability:
   â”œâ”€ Standby JobManager for failover
   â”œâ”€ Store state in ZooKeeper/K8s
   â””â”€ Recover from JobManager failure
```

**Configuration:**

```yaml
# flink-conf.yaml
jobmanager.memory.process.size: 1600m
jobmanager.rpc.address: localhost
jobmanager.rpc.port: 6123
jobmanager.bind-host: 0.0.0.0

# High Availability (ZooKeeper)
high-availability: zookeeper
high-availability.storageDir: hdfs:///flink/ha/
high-availability.zookeeper.quorum: zk1:2181,zk2:2181,zk3:2181
high-availability.zookeeper.path.root: /flink
```

---

### TaskManager Responsibilities

```
1. Task Execution:
   â”œâ”€ Execute operator tasks in slots
   â”œâ”€ Manage local state (memory or RocksDB)
   â”œâ”€ Buffer data for network transport
   â””â”€ Report metrics to JobManager

2. Network Communication:
   â”œâ”€ Send data to downstream operators (network buffers)
   â”œâ”€ Apply backpressure when buffers full
   â””â”€ Handle data shuffling (hash partitioning, broadcasting)

3. State Management:
   â”œâ”€ Store keyed state locally
   â”œâ”€ Participate in checkpointing
   â””â”€ Restore state from checkpoints

4. Resource Isolation:
   â”œâ”€ Each slot = isolated resources (CPU, memory)
   â”œâ”€ Slots can share pipeline (slot sharing)
   â””â”€ Prevents resource contention
```

**Configuration:**

```yaml
taskmanager.memory.process.size: 4096m
taskmanager.numberOfTaskSlots: 4
taskmanager.network.memory.fraction: 0.1
taskmanager.network.memory.min: 64mb
taskmanager.network.memory.max: 1gb

# Managed Memory (for RocksDB, sorting, etc.)
taskmanager.memory.managed.fraction: 0.4
```

---

### Task Slots and Parallelism

```
Example: 3 TaskManagers, 2 slots each = 6 total slots

Job with parallelism=6:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Operator: Source (parallelism=6)                            â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”‚
â”‚ â”‚Source-1â”‚ â”‚Source-2â”‚ â”‚Source-3â”‚ â”‚Source-4â”‚ â”‚Source-5â”‚ â”‚S.â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”‚
â”‚      â”‚          â”‚          â”‚          â”‚          â”‚       â”‚  â”‚
â”‚      â–¼          â–¼          â–¼          â–¼          â–¼       â–¼  â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”‚
â”‚ â”‚ Map-1  â”‚ â”‚ Map-2  â”‚ â”‚ Map-3  â”‚ â”‚ Map-4  â”‚ â”‚ Map-5  â”‚ â”‚M.â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”‚
â”‚      â”‚          â”‚          â”‚          â”‚          â”‚       â”‚  â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                           â”‚ (Hash Partition)                 â”‚
â”‚                           â–¼                                  â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”‚
â”‚ â”‚KeyBy-1 â”‚ â”‚KeyBy-2 â”‚ â”‚KeyBy-3 â”‚ â”‚KeyBy-4 â”‚ â”‚KeyBy-5 â”‚ â”‚K.â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Slot Allocation (with slot sharing):
TM1-Slot1: Source-1 â†’ Map-1 â†’ KeyBy-1
TM1-Slot2: Source-2 â†’ Map-2 â†’ KeyBy-2
TM2-Slot1: Source-3 â†’ Map-3 â†’ KeyBy-3
TM2-Slot2: Source-4 â†’ Map-4 â†’ KeyBy-4
TM3-Slot1: Source-5 â†’ Map-5 â†’ KeyBy-5
TM3-Slot2: Source-6 â†’ Map-6 â†’ KeyBy-6
```

**Key Concepts:**

```java
// Set parallelism at different levels:

// 1. Global default
env.setParallelism(4);

// 2. Per operator
stream
    .map(new MyMapper()).setParallelism(8)  // Override
    .keyBy(...)
    .window(...)
    .aggregate(new MyAgg()).setParallelism(4);  // Different parallelism

// 3. Command-line override
./bin/flink run -p 16 MyJob.jar
```

---

## ğŸ”’ 2. Checkpointing Internals

### Checkpoint Barrier Mechanism

```
Concept: Asynchronous Barrier Snapshotting (Chandy-Lamport variant)

Stream of events with barriers:

Source 1:  [e1] [e2] â”€â”€BARRIER(ckpt-5)â”€â”€ [e3] [e4]
Source 2:  [e5] â”€â”€BARRIER(ckpt-5)â”€â”€ [e6] [e7] [e8]
                    â”‚
                    â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Map Operator â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
When barrier arrives at operator:
1. Align barriers from all inputs (wait for slowest)
2. Snapshot local state
3. Acknowledge checkpoint to JobManager
4. Forward barrier to downstream operators
```

### Checkpoint Process (Step-by-Step)

```
Timeline of Checkpoint 5:

T=0ms:  JobManager triggers checkpoint 5
        â”œâ”€ Send RPC to all sources: "Emit barrier for ckpt-5"

T=5ms:  Sources emit barriers into streams
        â”œâ”€ Source-1: ... [e1] [e2] â”€â”€BARRIER(5)â”€â”€ [e3] ...
        â”œâ”€ Source-2: ... [e5] â”€â”€BARRIER(5)â”€â”€ [e6] ...
        â””â”€ Source-3: ... [e9] â”€â”€BARRIER(5)â”€â”€ [e10] ...

T=10ms: Barriers flow through operators
        â”œâ”€ Map operators receive barriers
        â”œâ”€ Snapshot local state (if any)
        â””â”€ Forward barriers downstream

T=15ms: KeyBy operators (stateful) receive barriers
        â”œâ”€ Align barriers from all upstream tasks
        â”œâ”€ Snapshot keyed state:
        â”‚  - ValueState, ListState, MapState
        â”‚  - Window buffers
        â”‚  - Timers
        â”œâ”€ Write state to state backend (async)
        â””â”€ Acknowledge to JobManager

T=20ms: JobManager receives all acknowledgments
        â”œâ”€ Mark checkpoint 5 as COMPLETED
        â”œâ”€ Store checkpoint metadata:
        â”‚  {
        â”‚    "checkpointId": 5,
        â”‚    "timestamp": 1697385600000,
        â”‚    "stateHandles": [
        â”‚      "s3://bucket/ckpt-5/task-1/state",
        â”‚      "s3://bucket/ckpt-5/task-2/state",
        â”‚      ...
        â”‚    ]
        â”‚  }
        â””â”€ Trigger cleanup of old checkpoints (ckpt-3)

Total latency: 20ms (typical for small state)
```

---

### Checkpoint Configuration

```java
StreamExecutionEnvironment env = 
    StreamExecutionEnvironment.getExecutionEnvironment();

// Enable checkpointing every 60 seconds
env.enableCheckpointing(60000);

// Checkpoint configuration
CheckpointConfig config = env.getCheckpointConfig();

// 1. Checkpoint mode (exactly-once vs at-least-once)
config.setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);

// 2. Minimum pause between checkpoints (avoid back-to-back)
config.setMinPauseBetweenCheckpoints(30000);  // 30 seconds

// 3. Checkpoint timeout (fail if not completed)
config.setCheckpointTimeout(300000);  // 5 minutes

// 4. Max concurrent checkpoints
config.setMaxConcurrentCheckpoints(1);  // Only 1 at a time

// 5. Externalized checkpoints (survive job cancellation)
config.enableExternalizedCheckpoints(
    ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION
);

// 6. Tolerate failed checkpoints
config.setTolerableCheckpointFailureNumber(3);  // Fail job after 3 failures

// 7. Unaligned checkpoints (faster for high backpressure)
config.enableUnalignedCheckpoints();
```

**State Backend Configuration:**

```java
// Store checkpoints in HDFS/S3
env.setStateBackend(new HashMapStateBackend());
env.getCheckpointConfig().setCheckpointStorage("s3://my-bucket/checkpoints");

// OR use RocksDB for large state
env.setStateBackend(new EmbeddedRocksDBStateBackend());
env.getCheckpointConfig().setCheckpointStorage("hdfs:///flink/checkpoints");
```

---

### Barrier Alignment vs Unaligned Checkpoints

```
Aligned Checkpoints (Default):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Input 1:  [e1] [e2] â”€â”€BARRIERâ”€â”€ [e3] [e4] [e5]        â”‚
â”‚ Input 2:  [e6] â”€â”€BARRIERâ”€â”€ [e7] [e8] [e9] [e10]       â”‚
â”‚                                                         â”‚
â”‚ Operator waits for barriers from ALL inputs:           â”‚
â”‚ â”œâ”€ Buffer events from Input 1 (e3, e4, e5)            â”‚
â”‚ â”œâ”€ Process events from Input 2 until barrier arrives  â”‚
â”‚ â””â”€ When both barriers received â†’ snapshot state       â”‚
â”‚                                                         â”‚
â”‚ Problem: High backpressure if one input is slow!      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Unaligned Checkpoints (Flink 1.11+):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Input 1:  [e1] [e2] â”€â”€BARRIERâ”€â”€ [e3] [e4] [e5]        â”‚
â”‚ Input 2:  [e6] â”€â”€BARRIERâ”€â”€ [e7] [e8] [e9] [e10]       â”‚
â”‚                                                         â”‚
â”‚ Operator snapshots state immediately when first        â”‚
â”‚ barrier arrives:                                        â”‚
â”‚ â”œâ”€ Snapshot in-flight buffers (e3, e4, e5)            â”‚
â”‚ â”œâ”€ Snapshot operator state                            â”‚
â”‚ â””â”€ Continue processing without blocking                â”‚
â”‚                                                         â”‚
â”‚ Benefit: Faster checkpoints under backpressure!       â”‚
â”‚ Cost: Larger checkpoint size (includes buffers)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’¾ 3. State Backends

### Comparison

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ State Backend       â”‚ Storage            â”‚ Use Case             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ HashMapStateBackend â”‚ JVM Heap           â”‚ Small state (<100MB) â”‚
â”‚ (MemoryStateBackend)â”‚ (synchronous)      â”‚ Low latency          â”‚
â”‚                     â”‚                    â”‚ Development/testing  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ EmbeddedRocksDB     â”‚ Local disk (RocksDBâ”‚ Large state (>100GB) â”‚
â”‚ StateBackend        â”‚ LSM-tree)          â”‚ Production           â”‚
â”‚                     â”‚ (asynchronous)     â”‚ Disk I/O tolerance   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### HashMapStateBackend (In-Memory)

```java
import org.apache.flink.runtime.state.hashmap.HashMapStateBackend;
import org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage;

StreamExecutionEnvironment env = ...;

// State stored in JVM heap
env.setStateBackend(new HashMapStateBackend());

// Checkpoints written to filesystem
env.getCheckpointConfig().setCheckpointStorage(
    new FileSystemCheckpointStorage("s3://my-bucket/checkpoints")
);
```

**Architecture:**

```
TaskManager JVM Heap:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Task Slot 1:                                     â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Keyed State (HashMap):                       â”‚ â”‚
â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚ â”‚
â”‚ â”‚ â”‚ user_id=123 â†’ ValueState(count=5)  â”‚       â”‚ â”‚
â”‚ â”‚ â”‚ user_id=456 â†’ ValueState(count=12) â”‚       â”‚ â”‚
â”‚ â”‚ â”‚ user_id=789 â†’ ValueState(count=3)  â”‚       â”‚ â”‚
â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Checkpoint:
â”œâ”€ Serialize HashMap â†’ byte[]
â”œâ”€ Write to S3/HDFS (synchronously)
â””â”€ Checkpoint completes when all writes finish
```

**Pros:**
- Ultra-low latency (no disk I/O)
- Simple configuration

**Cons:**
- Limited by JVM heap size
- Full GC pauses for large state
- Synchronous checkpoints (blocks processing)

---

### EmbeddedRocksDBStateBackend (Disk-Based)

```java
import org.apache.flink.contrib.streaming.state.EmbeddedRocksDBStateBackend;
import org.apache.flink.contrib.streaming.state.PredefinedOptions;

StreamExecutionEnvironment env = ...;

EmbeddedRocksDBStateBackend rocksDB = new EmbeddedRocksDBStateBackend();

// Predefined tuning profiles
rocksDB.setPredefinedOptions(PredefinedOptions.SPINNING_DISK_OPTIMIZED);
// OR: FLASH_SSD_OPTIMIZED, SPINNING_DISK_OPTIMIZED_HIGH_MEM

// Custom RocksDB options
rocksDB.setOptions(new OptionsFactory() {
    @Override
    public DBOptions createDBOptions(DBOptions currentOptions, Collection<AutoCloseable> handlesToClose) {
        return currentOptions
            .setMaxBackgroundJobs(4)
            .setMaxOpenFiles(1000);
    }
    
    @Override
    public ColumnFamilyOptions createColumnOptions(ColumnFamilyOptions currentOptions, Collection<AutoCloseable> handlesToClose) {
        return currentOptions
            .setCompactionStyle(CompactionStyle.LEVEL)
            .setWriteBufferSize(64 * 1024 * 1024);  // 64 MB
    }
});

env.setStateBackend(rocksDB);
env.getCheckpointConfig().setCheckpointStorage("s3://my-bucket/checkpoints");
```

**Architecture:**

```
TaskManager Local Disk (RocksDB):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ /tmp/flink-state/                                â”‚
â”‚ â”œâ”€ operator-1/                                   â”‚
â”‚ â”‚  â”œâ”€ db/ (RocksDB files)                        â”‚
â”‚ â”‚  â”‚  â”œâ”€ 000123.sst (Level 0)                    â”‚
â”‚ â”‚  â”‚  â”œâ”€ 000456.sst (Level 1)                    â”‚
â”‚ â”‚  â”‚  â””â”€ MANIFEST                                â”‚
â”‚ â”‚  â””â”€ checkpoint-5/ (incremental checkpoint)     â”‚
â”‚ â”‚     â”œâ”€ shared/ (SST files unchanged)           â”‚
â”‚ â”‚     â””â”€ private/ (new SST files)                â”‚
â”‚ â””â”€ operator-2/                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

State Access:
â”œâ”€ get(key) â†’ RocksDB JNI call â†’ Read from disk (cached in block cache)
â”œâ”€ put(key, value) â†’ Write to memtable â†’ Flush to SST
â””â”€ Asynchronous background compaction
```

**Incremental Checkpointing:**

```
Checkpoint 1:  [sst-1, sst-2, sst-3]
Checkpoint 2:  [sst-1, sst-2, sst-4, sst-5]  (reuse sst-1, sst-2)
Checkpoint 3:  [sst-1, sst-4, sst-6]          (reuse sst-1, sst-4)

Only new/modified SST files are uploaded!
Reduces checkpoint time from minutes to seconds.
```

```java
rocksDB.enableIncrementalCheckpointing(true);
```

**Pros:**
- Supports state > TaskManager memory
- Asynchronous snapshots (no blocking)
- Incremental checkpoints (faster)

**Cons:**
- Higher latency (disk I/O)
- RocksDB tuning required
- Disk space requirements

---

## âš™ï¸ 4. ProcessFunction: Custom Operators

### KeyedProcessFunction

```java
import org.apache.flink.streaming.api.functions.KeyedProcessFunction;
import org.apache.flink.util.Collector;

public class TimeoutDetector extends KeyedProcessFunction<String, Event, Alert> {
    
    private ValueState<Long> lastEventTimeState;
    
    @Override
    public void open(Configuration config) {
        ValueStateDescriptor<Long> descriptor = 
            new ValueStateDescriptor<>("lastEventTime", Long.class);
        lastEventTimeState = getRuntimeContext().getState(descriptor);
    }
    
    @Override
    public void processElement(
        Event event,
        Context ctx,
        Collector<Alert> out
    ) throws Exception {
        
        // Update last event time
        lastEventTimeState.update(event.getTimestamp());
        
        // Register timer: Fire if no event in next 60 seconds
        long timerTimestamp = event.getTimestamp() + 60_000;
        ctx.timerService().registerEventTimeTimer(timerTimestamp);
    }
    
    @Override
    public void onTimer(
        long timestamp,
        OnTimerContext ctx,
        Collector<Alert> out
    ) throws Exception {
        
        Long lastEventTime = lastEventTimeState.value();
        
        // Check if timeout occurred (no event in 60 seconds)
        if (timestamp - lastEventTime >= 60_000) {
            out.collect(new Alert(
                ctx.getCurrentKey(),
                "No activity for 60 seconds"
            ));
        }
    }
}
```

**Usage:**

```java
stream
    .keyBy(event -> event.getUserId())
    .process(new TimeoutDetector());
```

---

### Side Outputs (Multi-Stream Output)

```java
public class SplitStream extends ProcessFunction<Event, Event> {
    
    // Define side output tags
    private static final OutputTag<Event> highValueTag = 
        new OutputTag<Event>("high-value"){};
    
    private static final OutputTag<Event> lowValueTag = 
        new OutputTag<Event>("low-value"){};
    
    @Override
    public void processElement(
        Event event,
        Context ctx,
        Collector<Event> out
    ) {
        if (event.getValue() > 1000) {
            ctx.output(highValueTag, event);  // Side output
        } else if (event.getValue() < 100) {
            ctx.output(lowValueTag, event);   // Side output
        } else {
            out.collect(event);  // Main output
        }
    }
}

// Usage:
SingleOutputStreamOperator<Event> mainStream = stream.process(new SplitStream());

DataStream<Event> highValueStream = mainStream.getSideOutput(highValueTag);
DataStream<Event> lowValueStream = mainStream.getSideOutput(lowValueTag);
```

---

## ğŸ“ˆ 5. Performance Optimization

### Parallelism Tuning

```
Rule of thumb:
â”œâ”€ Parallelism = Number of Kafka partitions (for source alignment)
â”œâ”€ Slots per TaskManager = Number of CPU cores
â””â”€ TaskManagers = Total parallelism / slots per TM

Example:
â”œâ”€ Kafka topic: 64 partitions
â”œâ”€ Desired parallelism: 64
â”œâ”€ TaskManager: 8 slots (8-core machines)
â””â”€ Required TaskManagers: 64 / 8 = 8
```

```java
// Set parallelism to match Kafka partitions
env.setParallelism(64);

// Source inherits parallelism (64 parallel consumers)
DataStream<Event> stream = env.addSource(kafkaConsumer);

// Reduce parallelism for aggregation (fewer keys)
stream
    .keyBy(...)
    .window(...)
    .aggregate(new MyAgg()).setParallelism(16);  // Only 16 parallel aggregations
```

---

### Network Buffers

```yaml
# flink-conf.yaml

# Network buffer configuration
taskmanager.network.memory.fraction: 0.1
taskmanager.network.memory.min: 64mb
taskmanager.network.memory.max: 1gb

# Number of network buffers per channel
taskmanager.network.memory.buffers-per-channel: 2
taskmanager.network.memory.floating-buffers-per-gate: 8

# Buffer timeout (trade-off: latency vs throughput)
# Low value (0ms): Lower latency, more network overhead
# High value (100ms): Higher throughput, higher latency
env.setBufferTimeout(100);  // milliseconds
```

**Buffer Timeout Trade-Off:**

```
Buffer Timeout = 0ms (low latency):
â”œâ”€ Send buffer immediately (even if not full)
â”œâ”€ Latency: ~10ms
â””â”€ Throughput: 500k records/sec

Buffer Timeout = 100ms (high throughput):
â”œâ”€ Wait for buffer to fill before sending
â”œâ”€ Latency: ~100ms
â””â”€ Throughput: 2M records/sec
```

---

### Watermark Intervals

```java
// Global watermark interval (default: 200ms)
env.getConfig().setAutoWatermarkInterval(200);

// Custom watermark generator with periodic emission
public class BoundedOutOfOrdernessGenerator 
    implements WatermarkGenerator<Event> {
    
    private long maxTimestamp = Long.MIN_VALUE;
    private final long maxOutOfOrderness = 5000;  // 5 seconds
    
    @Override
    public void onEvent(Event event, long eventTimestamp, WatermarkOutput output) {
        maxTimestamp = Math.max(maxTimestamp, event.getTimestamp());
    }
    
    @Override
    public void onPeriodicEmit(WatermarkOutput output) {
        // Emit watermark every 200ms (configured above)
        output.emitWatermark(new Watermark(maxTimestamp - maxOutOfOrderness));
    }
}
```

---

## ğŸ” 6. Monitoring and Metrics

### Web UI Metrics

```
http://localhost:8081

Key metrics:
â”œâ”€ Checkpoint Duration: Should be < checkpoint interval
â”œâ”€ Checkpoint Size: Monitor growth over time
â”œâ”€ Backpressure: Red = high backpressure (bottleneck)
â”œâ”€ Records Sent/Received: Balance across operators
â””â”€ CPU/Memory Usage: Detect resource exhaustion
```

### Custom Metrics

```java
import org.apache.flink.metrics.Counter;
import org.apache.flink.api.common.functions.RichMapFunction;

public class CountingMapper extends RichMapFunction<Event, Event> {
    
    private transient Counter counter;
    
    @Override
    public void open(Configuration config) {
        this.counter = getRuntimeContext()
            .getMetricGroup()
            .counter("events_processed");
    }
    
    @Override
    public Event map(Event event) {
        counter.inc();
        return event;
    }
}
```

---

## ğŸ† Interview Questions (Intermediate Level)

1. **Explain the role of JobManager vs TaskManager.**
2. **How does barrier alignment work in checkpointing?**
3. **What are the differences between HashMapStateBackend and RocksDBStateBackend?**
4. **How would you tune Flink for low latency vs high throughput?**
5. **What are unaligned checkpoints and when should you use them?**
6. **How does Flink achieve exactly-once semantics?**
7. **What is slot sharing and why is it important?**

---

## ğŸ“ Summary Checklist

- [ ] Understand JobManager and TaskManager architecture
- [ ] Explain checkpoint barrier mechanism
- [ ] Configure state backends (HashMap vs RocksDB)
- [ ] Implement custom ProcessFunctions
- [ ] Optimize parallelism and network buffers
- [ ] Monitor Flink jobs with Web UI
- [ ] Answer intermediate interview questions

**Next:** [EXPERT.md â†’](EXPERT.md)
