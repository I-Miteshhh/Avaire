# Week 10: Anycast Implementation & Edge Computing ğŸŒâš¡

*"Edge computing is like having a mini-brain in every neighborhood that can think and act locally, while still coordinating with the global mind"*

## ğŸ¯ This Week's Mission
Master anycast network implementation and edge computing platforms. Learn how companies deploy compute resources globally, maintain consistency across edge locations, and optimize for millisecond-level performance at planetary scale.

---

## ğŸ“‹ Prerequisites: Building on Previous Weeks

You should now understand:
- âœ… **Global DNS Routing**: GeoDNS and intelligent traffic steering
- âœ… **Anycast Concepts**: Same IP address, multiple locations
- âœ… **CDN Architecture**: Content distribution and caching strategies
- âœ… **Microservices**: Distributed system communication patterns

### New Concepts We'll Master
- **BGP Anycast**: Border Gateway Protocol for anycast routing
- **Edge Functions**: Running code at CDN edge locations
- **Distributed State Management**: Consistency across edge nodes
- **Edge-to-Origin Communication**: Hybrid edge/cloud architectures

---

## ğŸª Explain Like I'm 10: The Neighborhood Smart Library Network

### ğŸ“š The Old Way: Central Library Only (Cloud Computing)

Imagine your city has **one giant library downtown**:

```
ğŸ¢ Central Downtown Library
â”œâ”€ 1 million books (complete collection)
â”œâ”€ Expert librarians (powerful computers)
â”œâ”€ Research labs (data processing)
â””â”€ Location: Downtown (30 minutes away)

Reading a Book Process:
You â†’ ğŸšŒ Bus to downtown (30 min) â†’ Find book (5 min) â†’ Read â†’ ğŸšŒ Bus home (30 min)
Total time: 65+ minutes just to check a simple fact!

Problems:
- Long travel time (high latency)
- Library crowded during peak hours (bottlenecks)
- If library closes â†’ No books for anyone (single point of failure)
- Everyone must go downtown (network congestion)
```

### ğŸ˜ï¸ The Smart Way: Neighborhood Smart Libraries (Edge Computing)

Now imagine **smart mini-libraries in every neighborhood**:

```
ğŸ˜ï¸ Neighborhood Smart Library Network

Your Neighborhood (5-minute walk):
â”œâ”€ 1,000 popular books (cached content)
â”œâ”€ Self-service kiosks (edge functions)
â”œâ”€ Local reading room (edge compute)
â””â”€ Connected to downtown (can request any book)

Next Neighborhood (15-minute walk):
â”œâ”€ Same 1,000 popular books
â”œâ”€ Same self-service kiosks
â”œâ”€ Same local capabilities
â””â”€ Also connected to downtown

Magic Features:
1. Quick Access: Walk 5 min instead of bus 30 min
2. Smart Caching: Popular books always available locally
3. Local Processing: Simple questions answered immediately
4. Backup Power: If one library closes, go to next one
5. Downtown Connection: Rare books fetched from central library
```

### ğŸ§  The Anycast Magic: Same Address, Closest Location

Here's the **brilliant part** - all libraries have the **same address**:

```
Every Library's Address: "123 Library Street"

You ask Google Maps: "Navigate to 123 Library Street"
Google Maps: 
â”œâ”€ Detects your location: North Neighborhood
â”œâ”€ Finds closest "123 Library Street": 5 min walk  
â”œâ”€ Gives directions to YOUR neighborhood library
â””â”€ Result: You arrive at closest location automatically!

Your Friend in South Neighborhood:
â”œâ”€ Same address: "123 Library Street"
â”œâ”€ Google Maps detects: South Neighborhood
â”œâ”€ Routes to South neighborhood library (also 5 min)
â””â”€ Different building, same address, same service!

Benefits:
- One simple address to remember
- Always go to closest location automatically
- If your local library is full â†’ Auto-routes to next closest
- New libraries added without changing address
```

### ğŸ”„ The Distributed Brain: How Libraries Stay Synchronized

The **smart library network** coordinates like this:

```
ğŸ“– Popular New Book Released: "Dragons of 2025"

Day 1 - Downtown Receives Book:
ğŸ¢ Central Library â†’ Receives 1,000 copies
                   â†“
         Monitors reader demand
                   â†“
         "This book is trending!"

Day 2 - Smart Distribution:
ğŸ¢ Central Library â†’ Sends to all neighborhood libraries
                   â†“
ğŸ˜ï¸ All neighborhood libraries receive copies
                   â†“
         Now available everywhere in 5 minutes!

Day 3 - Local Processing:
Student: "I need to write a report on dragons"
ğŸ˜ï¸ Neighborhood Library Kiosk:
â”œâ”€ Has "Dragons of 2025" book âœ“
â”œâ”€ Has AI assistant to help with research âœ“
â”œâ”€ Can print summary immediately âœ“
â””â”€ No need to call downtown!

Week Later - Smart Coordination:
North Library: "Dragons book checked out 50 times!"
South Library: "Only checked out 5 times here"
ğŸ¢ Central Library: "Move extra copies from South to North"
         â†“
Network auto-balances based on demand!
```

### âš¡ Edge Functions: Smart Robots in Every Library

Each library has **smart robot assistants** (edge functions):

```
ğŸ¤– Library Robot Capabilities:

Simple Questions (Answered Locally):
Student: "What time does library open?"
Robot: "9 AM - instant answer from local memory"

Medium Questions (Use Local Books):
Student: "Summarize this chapter about dragons"
Robot: "Reads book â†’ Generates summary â†’ 30 seconds"

Complex Questions (Call Downtown):  
Student: "Cross-reference dragons in all 1M books"
Robot: "Too complex for me â†’ Calling central library..."
ğŸ¢ Central: "Processing... results in 5 minutes"

Benefits:
- 80% of questions answered instantly (local)
- 15% of questions answered in seconds (local processing)
- 5% of complex questions use central library (acceptable delay)
```

---

## ğŸ—ï¸ Principal Architect Depth: Edge Computing at Global Scale

### ğŸš¨ The Edge Computing Architecture Challenge

#### Challenge 1: BGP Anycast Network Implementation
```
Border Gateway Protocol Anycast Setup:

Traditional Internet Routing:
â”œâ”€ Each server has unique IP address
â”œâ”€ Internet routes to specific location  
â”œâ”€ No automatic failover
â””â”€ Manual DNS changes for routing

Anycast Implementation with BGP:

Step 1: Configure Same IP at Multiple Locations
Virginia Data Center â†’ Announces 192.0.2.1/32 via AS64512
London Data Center â†’ Announces 192.0.2.1/32 via AS64513
Tokyo Data Center â†’ Announces 192.0.2.1/32 via AS64514

Step 2: BGP Propagation
Each data center advertises to upstream ISPs:
â”œâ”€ Virginia â†’ Verizon, Level3, Cogent
â”œâ”€ London â†’ BT, Telia, LINX
â””â”€ Tokyo â†’ NTT, KDDI, JPIX

Step 3: Internet Routing Decision
User in New York requests 192.0.2.1:
â”œâ”€ Local router checks BGP table
â”œâ”€ Sees 3 paths to 192.0.2.1:
â”‚   â”œâ”€ Via Verizon â†’ Virginia (2 hops) â† Shortest!
â”‚   â”œâ”€ Via Telia â†’ London (6 hops)
â”‚   â””â”€ Via NTT â†’ Tokyo (12 hops)
â”œâ”€ Selects Virginia (shortest AS path)
â””â”€ Routes traffic automatically

Automatic Failover:
Virginia data center goes down:
â”œâ”€ Stops announcing 192.0.2.1
â”œâ”€ BGP propagates withdrawal (30-180 seconds)
â”œâ”€ New York traffic now routes to London  
â”œâ”€ Users experience brief disruption, then automatic recovery
â””â”€ No manual intervention required!
```

#### Challenge 2: Edge Computing Execution Models
```
Edge Function Deployment Patterns:

Pattern 1: CDN Edge Workers (Cloudflare Workers, Fastly Compute@Edge)
Deployment Model:
â”œâ”€ JavaScript/WebAssembly code
â”œâ”€ Deployed to 200+ global locations  
â”œâ”€ Isolated V8 runtime per request
â”œâ”€ 0-5ms cold start time
â””â”€ Sub-millisecond execution for simple logic

Use Cases:
â”œâ”€ Request/response manipulation (add headers, modify URLs)
â”œâ”€ A/B testing and feature flags
â”œâ”€ API gateway and authentication
â”œâ”€ Simple business logic (rate limiting, validation)
â””â”€ Edge caching decisions

Constraints:
â”œâ”€ Execution time limit: 50-200ms
â”œâ”€ Memory limit: 128MB-512MB
â”œâ”€ No local filesystem
â”œâ”€ Limited CPU time
â””â”€ Stateless (ephemeral storage only)

Pattern 2: Edge Containers (AWS Lambda@Edge, Azure Edge Zones)
Deployment Model:  
â”œâ”€ Container or function package
â”œâ”€ Deployed to regional edge locations (20-50 globally)
â”œâ”€ Container runtime (Docker-compatible)
â”œâ”€ 100-500ms cold start time
â””â”€ Longer execution allowed (up to 30 seconds)

Use Cases:
â”œâ”€ Image/video processing and transformation
â”œâ”€ Complex API aggregation
â”œâ”€ Server-side rendering (SSR)
â”œâ”€ Machine learning inference
â””â”€ Database queries and aggregations

Constraints:
â”œâ”€ Higher cold start latency
â”œâ”€ Fewer global locations
â”œâ”€ More expensive per request
â””â”€ Still limited by edge location resources

Pattern 3: Edge Kubernetes (Google Anthos, Azure Arc)
Deployment Model:
â”œâ”€ Full Kubernetes clusters at edge
â”œâ”€ Deployed to specific customer locations
â”œâ”€ Complete container orchestration
â”œâ”€ Persistent storage available
â””â”€ Can run any workload

Use Cases:
â”œâ”€ IoT data processing at source
â”œâ”€ Manufacturing floor automation
â”œâ”€ Retail point-of-sale systems
â”œâ”€ 5G network functions
â””â”€ Latency-critical applications

Constraints:
â”œâ”€ Higher infrastructure cost
â”œâ”€ Complex operational overhead
â”œâ”€ Requires local hardware
â””â”€ Network connectivity dependencies
```

### ğŸŒ Distributed State Management at Edge

#### Edge Data Consistency Strategies
```
Challenge: Keep data synchronized across 200+ edge locations

Strategy 1: Eventually Consistent Edge Cache
Architecture:
Origin DB â†’ Regional Replication â†’ Edge Caches
   â†“              â†“                    â†“
MySQL       Read Replicas         Distributed Cache
(source)    (15 regions)         (200+ locations)

Update Flow:
1. Write to origin database (100ms)
2. Replicate to regional databases (1-5 seconds)
3. Edge caches invalidated (10-30 seconds)
4. Edge fetches fresh data on next request

Use Cases:
â”œâ”€ Product catalogs (changes infrequently)
â”œâ”€ User profiles (eventual consistency acceptable)
â”œâ”€ Content metadata
â””â”€ Configuration data

Consistency Model: Eventual (seconds to minutes)

Strategy 2: Distributed Edge Database (CRDTs)
Architecture:
Edge Location 1 â† â†’ Edge Location 2 â† â†’ Edge Location 3
     â†“                    â†“                    â†“
   CRDT DB            CRDT DB              CRDT DB
(Conflict-free)    (Auto-merge)         (Convergent)

Update Flow:
1. Write to local edge database (10ms)
2. Asynchronously sync to other edges (background)
3. Conflict-free merges using CRDT algorithms
4. All edges eventually converge to same state

CRDT Examples:
â”œâ”€ Counters: LWW (Last-Write-Wins) counter
â”œâ”€ Sets: OR-Set (Observed-Remove Set)
â”œâ”€ Maps: LWW-Map with tombstones
â””â”€ Registers: Multi-Value Register

Use Cases:
â”œâ”€ Collaborative editing (Google Docs)
â”œâ”€ Shopping cart state
â”œâ”€ User presence/status
â”œâ”€ Real-time analytics counters
â””â”€ Distributed configuration

Consistency Model: Strong eventual (automatic convergence)

Strategy 3: Edge-to-Origin Validation
Architecture:
Edge Compute â†’ Local Decision â†’ Origin Validation (if needed)

Decision Flow:
User Request â†’ Edge Function:
â”œâ”€ Check local cache (5ms)
â”œâ”€ If critical operation â†’ Validate with origin (100ms)
â”œâ”€ If read operation â†’ Use cached data (5ms)
â””â”€ If write operation â†’ Write to origin + invalidate caches

Use Cases:
â”œâ”€ Payment authorization (must validate)
â”œâ”€ Inventory checks (eventual consistency OK)
â”œâ”€ User authentication (cached with TTL)
â””â”€ Content delivery (cached with long TTL)

Consistency Model: Hybrid (critical=strong, others=eventual)
```

---

## ğŸŒ Real-World Implementation Examples

### ğŸ“Š Case Study 1: Cloudflare Workers - Serverless Edge Platform

**The Scale**: 275+ cities, 100+ countries, processing 35M+ requests/second

```
Cloudflare Workers Architecture:

Global Deployment:
â”œâ”€ JavaScript/WebAssembly code deployed globally
â”œâ”€ Executes in V8 isolates (not containers)
â”œâ”€ 0ms cold start (isolates are instant)
â”œâ”€ Automatic routing to nearest location
â””â”€ 100% CPU time included (no throttling)

Execution Environment:
â”œâ”€ V8 JavaScript engine
â”œâ”€ WebAssembly support (Rust, C++, Go compiled)
â”œâ”€ Service bindings (Worker-to-Worker calls)
â”œâ”€ KV storage (eventually consistent, global)
â”œâ”€ Durable Objects (strongly consistent, regional)
â””â”€ R2 object storage (S3-compatible, no egress fees)

Performance Characteristics:
â”œâ”€ Cold start: 0ms (isolates pre-warmed)
â”œâ”€ Execution time: median 1-2ms
â”œâ”€ P99 latency: <50ms globally
â”œâ”€ Throughput: 1M+ requests/sec per account
â””â”€ Memory: 128MB per request

Advanced Features:
â”œâ”€ Cron triggers (scheduled execution)
â”œâ”€ Queue integration (async messaging)
â”œâ”€ WebSocket support (real-time connections)
â”œâ”€ Image transformation (built-in)
â””â”€ Email routing and transformation
```

**Cloudflare Workers Real-World Performance**:
```
Production Performance Metrics:

E-commerce API Gateway:
â”œâ”€ Traditional cloud API: 200-300ms latency globally
â”œâ”€ Cloudflare Workers API: 15-40ms latency globally
â”œâ”€ Improvement: 85% latency reduction
â”œâ”€ Cost reduction: 60% (vs serverless cloud functions)
â””â”€ Scalability: Automatic (no capacity planning)

Authentication Layer:
â”œâ”€ JWT validation at edge (2-5ms)
â”œâ”€ Session check in Workers KV (10-15ms)
â”œâ”€ Total auth overhead: <20ms
â”œâ”€ Traditional auth: 100-200ms (origin round-trip)
â””â”€ User experience: Feels instant globally

A/B Testing Platform:
â”œâ”€ Traffic split decisions: <1ms at edge
â”œâ”€ Experiment tracking: Workers KV
â”œâ”€ Analytics: Sent to origin async
â”œâ”€ Zero impact on user latency
â””â”€ Real-time experimentation across globe

Developer Experience:
â”œâ”€ Deploy time: 30 seconds globally
â”œâ”€ Rollback time: 10 seconds
â”œâ”€ Local testing: Miniflare emulator
â”œâ”€ Debugging: Real-time logs and traces
â””â”€ Cost: $5/month + $0.50 per million requests
```

### ğŸ“Š Case Study 2: AWS Lambda@Edge with CloudFront

**The Innovation**: Run Lambda functions at 400+ CloudFront edge locations

```
Lambda@Edge Architecture:

Deployment Model:
â”œâ”€ Node.js or Python Lambda functions
â”œâ”€ Triggered by CloudFront events:
â”‚   â”œâ”€ Viewer Request (before cache check)
â”‚   â”œâ”€ Origin Request (after cache miss)
â”‚   â”œâ”€ Origin Response (after origin responds)
â”‚   â””â”€ Viewer Response (before returning to user)
â”œâ”€ Deployed from us-east-1 â†’ Replicated globally
â”œâ”€ Cold start: 100-500ms (first request per region)
â””â”€ Warm execution: 5-50ms

Use Cases and Implementations:

1. Dynamic Content Generation (Viewer Request):
```javascript
exports.handler = async (event) => {
    const request = event.Records[0].cf.request;
    const headers = request.headers;
    
    // Detect mobile devices
    const userAgent = headers['user-agent'][0].value;
    const isMobile = /Mobile|Android/i.test(userAgent);
    
    // Modify request to serve appropriate content
    if (isMobile) {
        request.uri = request.uri.replace('/web/', '/mobile/');
    }
    
    return request;
};
```

2. Security Headers Injection (Viewer Response):
```javascript
exports.handler = async (event) => {
    const response = event.Records[0].cf.response;
    
    // Add security headers at edge
    response.headers['strict-transport-security'] = [{
        key: 'Strict-Transport-Security',
        value: 'max-age=31536000; includeSubdomains; preload'
    }];
    
    response.headers['content-security-policy'] = [{
        key: 'Content-Security-Policy',
        value: "default-src 'self'; script-src 'self' 'unsafe-inline'"
    }];
    
    return response;
};
```

3. Image Optimization (Origin Response):
```javascript
const Sharp = require('sharp');

exports.handler = async (event) => {
    const response = event.Records[0].cf.response;
    const request = event.Records[0].cf.request;
    
    // Check if WebP is supported
    const accept = request.headers.accept?.[0]?.value || '';
    const supportsWebP = accept.includes('image/webp');
    
    if (supportsWebP && response.status === '200') {
        const imageBuffer = Buffer.from(response.body, 'base64');
        
        // Convert to WebP at edge
        const webpBuffer = await Sharp(imageBuffer)
            .webp({ quality: 80 })
            .toBuffer();
        
        response.body = webpBuffer.toString('base64');
        response.bodyEncoding = 'base64';
        response.headers['content-type'] = [{
            key: 'Content-Type',
            value: 'image/webp'
        }];
    }
    
    return response;
};
```

Performance Results:
â”œâ”€ Image optimization: 60% size reduction at edge
â”œâ”€ Security header injection: 0ms latency overhead
â”œâ”€ Dynamic routing: 5-10ms decision time
â”œâ”€ Global deployment: 2-3 minutes
â””â”€ Cost: $0.60 per 1M requests + $0.00001 per GB-second
```

### ğŸ“Š Case Study 3: Fastly Compute@Edge - WebAssembly at the Edge

**The Power**: Compile any language to WebAssembly, run at 70+ global locations

```
Fastly Compute@Edge Architecture:

Execution Environment:
â”œâ”€ WebAssembly runtime (Lucet JIT compiler)
â”œâ”€ Language support: Rust, JavaScript, Go, Python, C/C++
â”œâ”€ Cold start: 35-100Âµs (microseconds!)
â”œâ”€ Execution: Native speed (compiled to machine code)
â””â”€ Memory: Isolated, secure sandboxing

Performance Characteristics:
â”œâ”€ Startup: 50Âµs median (vs 100+ms for containers)
â”œâ”€ Execution: Near-native performance
â”œâ”€ Throughput: 1M+ requests/second per location
â”œâ”€ Latency: P50 <10ms, P99 <50ms globally
â””â”€ Efficiency: 100x more efficient than containers

Example: Rust-based Edge API
```rust
use fastly::{Error, Request, Response};
use serde_json::json;

#[fastly::main]
fn main(mut req: Request) -> Result<Response, Error> {
    // Parse request
    let client_ip = req.get_client_ip_addr()
        .map(|ip| ip.to_string())
        .unwrap_or_else(|| "unknown".to_string());
    
    // Geolocation lookup (built-in)
    let geo = req.get_client_geo_info()?;
    
    // Route based on geography
    let backend = match geo.country_code().as_deref() {
        Some("US") | Some("CA") => "us_backend",
        Some("GB") | Some("FR") | Some("DE") => "eu_backend",
        Some("JP") | Some("SG") | Some("AU") => "asia_backend",
        _ => "default_backend",
    };
    
    // Make backend request
    let mut backend_req = Request::get(format!(
        "https://{}/api/data",
        backend
    ));
    
    // Add custom headers
    backend_req.set_header("X-Client-IP", client_ip);
    backend_req.set_header("X-Client-Country", 
                          geo.country_code().unwrap_or("unknown"));
    
    // Send to backend
    let backend_resp = backend_req.send(backend)?;
    
    // Return response
    Ok(backend_resp)
}
```

Production Performance:
â”œâ”€ API routing latency: 5-8ms (including geo lookup)
â”œâ”€ Custom logic execution: 1-3ms
â”œâ”€ Backend selection: <1ms
â”œâ”€ Total request overhead: <10ms
â””â”€ Developer experience: Excellent (full language features)

Advanced Capabilities:
â”œâ”€ Edge-side rendering (SSR)
â”œâ”€ Real-time personalization
â”œâ”€ Complex routing logic
â”œâ”€ Protocol transformation
â””â”€ Security policy enforcement
```

---

## ğŸ§ª Hands-On Lab: Build Edge Computing Platform

### ğŸ” Experiment 1: Simple Edge Function Implementation

**Create edge workers for common use cases:**

```javascript
// Cloudflare Workers example: Intelligent routing and caching

addEventListener('fetch', event => {
    event.respondWith(handleRequest(event.request))
})

async function handleRequest(request) {
    const url = new URL(request.url);
    const cache = caches.default;
    
    // Check cache first
    let response = await cache.match(request);
    
    if (response) {
        // Cache hit - add header and return
        response = new Response(response.body, response);
        response.headers.set('X-Cache', 'HIT');
        return response;
    }
    
    // Cache miss - intelligent routing
    const origin = await selectOptimalOrigin(request);
    
    // Modify request for origin
    const originRequest = new Request(request);
    originRequest.headers.set('X-Edge-Location', 
        request.cf?.colo || 'unknown');
    
    // Fetch from selected origin
    response = await fetch(originRequest, {
        backend: origin,
        timeout: 10000
    });
    
    // Cache successful responses
    if (response.ok) {
        response = new Response(response.body, response);
        response.headers.set('X-Cache', 'MISS');
        response.headers.set('X-Origin', origin);
        
        // Determine cache TTL based on content type
        const contentType = response.headers.get('Content-Type') || '';
        let cacheTTL = 3600; // Default 1 hour
        
        if (contentType.includes('image/')) {
            cacheTTL = 86400; // Images: 24 hours
        } else if (contentType.includes('application/json')) {
            cacheTTL = 300; // API responses: 5 minutes
        } else if (contentType.includes('text/html')) {
            cacheTTL = 60; // HTML: 1 minute
        }
        
        response.headers.set('Cache-Control', `public, max-age=${cacheTTL}`);
        
        // Store in cache
        event.waitUntil(cache.put(request, response.clone()));
    }
    
    return response;
}

async function selectOptimalOrigin(request) {
    // Get client location from Cloudflare
    const country = request.cf?.country || 'US';
    const continent = request.cf?.continent || 'NA';
    
    // Route to nearest healthy origin
    const origins = {
        'NA': 'https://us-origin.example.com',
        'EU': 'https://eu-origin.example.com',
        'AS': 'https://asia-origin.example.com',
        'OC': 'https://aus-origin.example.com',
    };
    
    // Check origin health (simplified)
    const preferredOrigin = origins[continent] || origins['NA'];
    
    // Could implement sophisticated health checking here
    const isHealthy = await checkOriginHealth(preferredOrigin);
    
    if (isHealthy) {
        return preferredOrigin;
    } else {
        // Failover to primary origin
        return origins['NA'];
    }
}

async function checkOriginHealth(origin) {
    try {
        const healthCheck = await fetch(`${origin}/health`, {
            timeout: 2000
        });
        return healthCheck.ok;
    } catch (error) {
        return false;
    }
}

// A/B Testing at edge
addEventListener('fetch', event => {
    event.respondWith(handleABTest(event.request))
})

async function handleABTest(request) {
    const url = new URL(request.url);
    
    // Get or assign experiment variant
    const cookie = request.headers.get('Cookie') || '';
    let variant = getVariantFromCookie(cookie);
    
    if (!variant) {
        // Assign new user to variant (50/50 split)
        variant = Math.random() < 0.5 ? 'A' : 'B';
    }
    
    // Route to appropriate backend
    const backend = variant === 'A' 
        ? 'https://version-a.example.com'
        : 'https://version-b.example.com';
    
    const response = await fetch(backend + url.pathname, {
        headers: request.headers
    });
    
    // Set cookie to maintain variant assignment
    const newResponse = new Response(response.body, response);
    newResponse.headers.set('Set-Cookie', 
        `experiment_variant=${variant}; Path=/; Max-Age=2592000; SameSite=Lax`);
    newResponse.headers.set('X-Experiment-Variant', variant);
    
    return newResponse;
}

function getVariantFromCookie(cookie) {
    const match = cookie.match(/experiment_variant=([AB])/);
    return match ? match[1] : null;
}
```

### ğŸ” Experiment 2: Edge Database with CRDTs

**Implement distributed counter using Conflict-free Replicated Data Types:**

```python
import asyncio
import json
from dataclasses import dataclass, field
from typing import Dict, Set
import hashlib
import time

@dataclass
class GCounter:
    """
    Grow-only Counter CRDT
    Allows increments at any replica, automatically merges
    """
    node_id: str
    counts: Dict[str, int] = field(default_factory=dict)
    
    def increment(self, amount: int = 1):
        """Increment counter at this node"""
        if self.node_id not in self.counts:
            self.counts[self.node_id] = 0
        self.counts[self.node_id] += amount
    
    def value(self) -> int:
        """Get total counter value across all nodes"""
        return sum(self.counts.values())
    
    def merge(self, other: 'GCounter'):
        """Merge with another GCounter (conflict-free)"""
        for node_id, count in other.counts.items():
            current = self.counts.get(node_id, 0)
            # Take maximum value for each node
            self.counts[node_id] = max(current, count)
    
    def to_dict(self):
        return {
            'node_id': self.node_id,
            'counts': self.counts,
            'total': self.value()
        }

@dataclass
class PNCounter:
    """
    Positive-Negative Counter CRDT
    Allows both increments and decrements
    """
    node_id: str
    positive: GCounter = field(default_factory=lambda: GCounter(''))
    negative: GCounter = field(default_factory=lambda: GCounter(''))
    
    def __post_init__(self):
        self.positive.node_id = self.node_id
        self.negative.node_id = self.node_id
    
    def increment(self, amount: int = 1):
        """Increment counter"""
        self.positive.increment(amount)
    
    def decrement(self, amount: int = 1):
        """Decrement counter"""
        self.negative.increment(amount)
    
    def value(self) -> int:
        """Get net counter value"""
        return self.positive.value() - self.negative.value()
    
    def merge(self, other: 'PNCounter'):
        """Merge with another PNCounter"""
        self.positive.merge(other.positive)
        self.negative.merge(other.negative)
    
    def to_dict(self):
        return {
            'node_id': self.node_id,
            'value': self.value(),
            'positive': self.positive.to_dict(),
            'negative': self.negative.to_dict()
        }

@dataclass
class LWWRegister:
    """
    Last-Write-Wins Register CRDT
    Stores a value with timestamp, latest write wins
    """
    node_id: str
    value: any = None
    timestamp: float = 0.0
    writer_id: str = ''
    
    def write(self, value):
        """Write new value with current timestamp"""
        self.value = value
        self.timestamp = time.time()
        self.writer_id = self.node_id
    
    def merge(self, other: 'LWWRegister'):
        """Merge with another register, keeping latest write"""
        if other.timestamp > self.timestamp:
            self.value = other.value
            self.timestamp = other.timestamp
            self.writer_id = other.writer_id
        elif other.timestamp == self.timestamp:
            # Tie-breaker: use writer_id lexicographically
            if other.writer_id > self.writer_id:
                self.value = other.value
                self.writer_id = other.writer_id
    
    def to_dict(self):
        return {
            'value': self.value,
            'timestamp': self.timestamp,
            'writer_id': self.writer_id
        }

class EdgeNode:
    """
    Simulates an edge computing node with CRDT storage
    """
    def __init__(self, node_id: str, location: str):
        self.node_id = node_id
        self.location = location
        self.page_views = PNCounter(node_id)
        self.user_sessions = GCounter(node_id)
        self.feature_flag = LWWRegister(node_id)
        self.peers: Set['EdgeNode'] = set()
    
    def add_peer(self, peer: 'EdgeNode'):
        """Connect to another edge node"""
        self.peers.add(peer)
        peer.peers.add(self)
    
    async def sync_with_peers(self):
        """Synchronize CRDT state with all peers"""
        for peer in self.peers:
            # Send our state to peer
            await peer.receive_sync(self)
    
    async def receive_sync(self, peer: 'EdgeNode'):
        """Receive and merge state from peer"""
        # Merge all CRDTs
        self.page_views.merge(peer.page_views)
        self.user_sessions.merge(peer.user_sessions)
        self.feature_flag.merge(peer.feature_flag)
    
    def record_page_view(self):
        """Record a page view at this edge location"""
        self.page_views.increment(1)
    
    def record_session(self):
        """Record a new user session"""
        self.user_sessions.increment(1)
    
    def update_feature_flag(self, enabled: bool):
        """Update feature flag"""
        self.feature_flag.write(enabled)
    
    def get_stats(self):
        """Get current statistics"""
        return {
            'node_id': self.node_id,
            'location': self.location,
            'total_page_views': self.page_views.value(),
            'total_sessions': self.user_sessions.value(),
            'feature_enabled': self.feature_flag.value,
            'last_feature_update': self.feature_flag.timestamp
        }

# Simulate edge network with CRDTs
async def simulate_edge_network():
    """
    Simulate a global edge network with multiple nodes
    using CRDTs for distributed state management
    """
    # Create edge nodes in different locations
    nodes = {
        'us-west': EdgeNode('us-west', 'California'),
        'us-east': EdgeNode('us-east', 'Virginia'),
        'eu-west': EdgeNode('eu-west', 'Ireland'),
        'asia-se': EdgeNode('asia-se', 'Singapore'),
        'asia-ne': EdgeNode('asia-ne', 'Tokyo'),
    }
    
    # Connect nodes in a mesh network
    node_list = list(nodes.values())
    for i, node in enumerate(node_list):
        for peer in node_list[i+1:]:
            node.add_peer(peer)
    
    print("ğŸŒ Edge Network Initialized")
    print(f"Nodes: {list(nodes.keys())}")
    print(f"Mesh connections: {len(node_list) * (len(node_list)-1) // 2}\n")
    
    # Simulate traffic at different edge locations
    print("ğŸ“Š Simulating User Traffic...")
    
    # California gets high traffic
    for _ in range(100):
        nodes['us-west'].record_page_view()
        if _ % 10 == 0:
            nodes['us-west'].record_session()
    
    # Virginia gets medium traffic
    for _ in range(60):
        nodes['us-east'].record_page_view()
        if _ % 8 == 0:
            nodes['us-east'].record_session()
    
    # Ireland gets medium traffic
    for _ in range(70):
        nodes['eu-west'].record_page_view()
        if _ % 7 == 0:
            nodes['eu-west'].record_session()
    
    # Singapore gets low traffic
    for _ in range(30):
        nodes['asia-se'].record_page_view()
        if _ % 5 == 0:
            nodes['asia-se'].record_session()
    
    # Tokyo gets low traffic
    for _ in range(40):
        nodes['asia-ne'].record_page_view()
        if _ % 6 == 0:
            nodes['asia-ne'].record_session()
    
    # Feature flag update from Ireland
    nodes['eu-west'].update_feature_flag(True)
    
    print("\nğŸ“¡ Before Synchronization:")
    for name, node in nodes.items():
        stats = node.get_stats()
        print(f"{name}: {stats['total_page_views']} views, "
              f"{stats['total_sessions']} sessions, "
              f"feature={stats['feature_enabled']}")
    
    # Synchronize all nodes
    print("\nğŸ”„ Synchronizing Edge Nodes...")
    sync_tasks = [node.sync_with_peers() for node in nodes.values()]
    await asyncio.gather(*sync_tasks)
    
    # Small delay for realism
    await asyncio.sleep(0.1)
    
    print("\nâœ… After Synchronization:")
    for name, node in nodes.items():
        stats = node.get_stats()
        print(f"{name}: {stats['total_page_views']} views, "
              f"{stats['total_sessions']} sessions, "
              f"feature={stats['feature_enabled']}")
    
    # Verify all nodes converged to same state
    values = [node.page_views.value() for node in nodes.values()]
    sessions = [node.user_sessions.value() for node in nodes.values()]
    flags = [node.feature_flag.value for node in nodes.values()]
    
    print(f"\nğŸ¯ Convergence Check:")
    print(f"All nodes agree on page views: {len(set(values)) == 1} (value: {values[0]})")
    print(f"All nodes agree on sessions: {len(set(sessions)) == 1} (value: {sessions[0]})")
    print(f"All nodes agree on feature flag: {len(set(flags)) == 1} (value: {flags[0]})")
    
    # Demonstrate conflict-free merging
    print(f"\nğŸ”¬ CRDT Properties Demonstrated:")
    print(f"âœ“ Commutative: Merge order doesn't matter")
    print(f"âœ“ Associative: Can merge in any grouping")
    print(f"âœ“ Idempotent: Merging same state multiple times is safe")
    print(f"âœ“ Eventual Consistency: All nodes converge to same state")

# Run the simulation
if __name__ == "__main__":
    asyncio.run(simulate_edge_network())
```

### ğŸ” Experiment 3: Edge-to-Origin Hybrid Architecture

**Implement intelligent edge caching with origin fallback:**

```python
import asyncio
import aiohttp
import time
from enum import Enum
from dataclasses import dataclass
from typing import Optional, Dict
import hashlib
import json

class CacheStrategy(Enum):
    EDGE_FIRST = "edge_first"  # Try edge, fallback to origin
    ORIGIN_FIRST = "origin_first"  # Always fetch from origin
    EDGE_ONLY = "edge_only"  # Only use edge (fail if not cached)

@dataclass
class CachedData:
    data: any
    timestamp: float
    ttl: int
    etag: str
    
    def is_expired(self) -> bool:
        return time.time() > (self.timestamp + self.ttl)
    
    def is_stale(self, stale_threshold: int = 60) -> bool:
        """Check if data is stale but might be acceptable"""
        age = time.time() - self.timestamp
        return age > (self.ttl - stale_threshold)

class EdgeOriginCache:
    """
    Hybrid edge-to-origin caching system
    Demonstrates stale-while-revalidate and other advanced patterns
    """
    def __init__(self, node_id: str, origin_url: str):
        self.node_id = node_id
        self.origin_url = origin_url
        self.cache: Dict[str, CachedData] = {}
        self.revalidation_in_progress: Dict[str, asyncio.Event] = {}
        
        # Metrics
        self.stats = {
            'edge_hits': 0,
            'edge_misses': 0,
            'origin_requests': 0,
            'stale_while_revalidate': 0,
            'revalidations': 0
        }
    
    async def get(self, key: str, strategy: CacheStrategy = CacheStrategy.EDGE_FIRST,
                  ttl: int = 300, stale_while_revalidate: bool = True) -> Optional[dict]:
        """
        Get data with specified caching strategy
        """
        cache_key = self._make_cache_key(key)
        
        if strategy == CacheStrategy.EDGE_ONLY:
            return await self._get_edge_only(cache_key)
        elif strategy == CacheStrategy.ORIGIN_FIRST:
            return await self._get_origin_first(cache_key, ttl)
        else:  # EDGE_FIRST
            return await self._get_edge_first(
                cache_key, ttl, stale_while_revalidate
            )
    
    async def _get_edge_only(self, cache_key: str) -> Optional[dict]:
        """Get from edge cache only, fail if not available"""
        cached = self.cache.get(cache_key)
        
        if cached and not cached.is_expired():
            self.stats['edge_hits'] += 1
            return {
                'data': cached.data,
                'source': 'edge_cache',
                'age_seconds': time.time() - cached.timestamp
            }
        
        self.stats['edge_misses'] += 1
        return None
    
    async def _get_origin_first(self, cache_key: str, ttl: int) -> dict:
        """Always fetch from origin (cache-aside pattern)"""
        data = await self._fetch_from_origin(cache_key)
        
        if data:
            # Cache the result
            self.cache[cache_key] = CachedData(
                data=data,
                timestamp=time.time(),
                ttl=ttl,
                etag=self._generate_etag(data)
            )
        
        return {
            'data': data,
            'source': 'origin',
            'cached_at_edge': data is not None
        }
    
    async def _get_edge_first(self, cache_key: str, ttl: int,
                             stale_while_revalidate: bool) -> dict:
        """
        Try edge cache first, implement stale-while-revalidate
        """
        cached = self.cache.get(cache_key)
        
        # Case 1: Fresh cache hit
        if cached and not cached.is_expired():
            self.stats['edge_hits'] += 1
            
            # Check if stale and should revalidate in background
            if cached.is_stale() and stale_while_revalidate:
                # Return stale data immediately
                self.stats['stale_while_revalidate'] += 1
                
                # Revalidate in background (don't await)
                asyncio.create_task(
                    self._revalidate_in_background(cache_key, ttl)
                )
                
                return {
                    'data': cached.data,
                    'source': 'edge_cache_stale_revalidating',
                    'age_seconds': time.time() - cached.timestamp
                }
            
            return {
                'data': cached.data,
                'source': 'edge_cache_fresh',
                'age_seconds': time.time() - cached.timestamp
            }
        
        # Case 2: Cache miss or expired - fetch from origin
        self.stats['edge_misses'] += 1
        
        # Check if revalidation already in progress
        if cache_key in self.revalidation_in_progress:
            # Wait for ongoing revalidation
            await self.revalidation_in_progress[cache_key].wait()
            # Try cache again
            cached = self.cache.get(cache_key)
            if cached:
                return {
                    'data': cached.data,
                    'source': 'edge_cache_after_wait',
                    'age_seconds': time.time() - cached.timestamp
                }
        
        # Fetch from origin
        data = await self._fetch_from_origin(cache_key)
        
        if data:
            self.cache[cache_key] = CachedData(
                data=data,
                timestamp=time.time(),
                ttl=ttl,
                etag=self._generate_etag(data)
            )
            
            return {
                'data': data,
                'source': 'origin_fresh',
                'age_seconds': 0
            }
        
        # Origin failed - return stale if available
        if cached:
            return {
                'data': cached.data,
                'source': 'edge_cache_stale_fallback',
                'age_seconds': time.time() - cached.timestamp,
                'warning': 'origin_unavailable'
            }
        
        return {'data': None, 'source': 'failed', 'error': 'origin_unavailable'}
    
    async def _revalidate_in_background(self, cache_key: str, ttl: int):
        """Background revalidation for stale-while-revalidate"""
        if cache_key in self.revalidation_in_progress:
            return  # Already revalidating
        
        event = asyncio.Event()
        self.revalidation_in_progress[cache_key] = event
        
        try:
            self.stats['revalidations'] += 1
            data = await self._fetch_from_origin(cache_key)
            
            if data:
                self.cache[cache_key] = CachedData(
                    data=data,
                    timestamp=time.time(),
                    ttl=ttl,
                    etag=self._generate_etag(data)
                )
        finally:
            del self.revalidation_in_progress[cache_key]
            event.set()
    
    async def _fetch_from_origin(self, cache_key: str) -> Optional[dict]:
        """Fetch data from origin server"""
        self.stats['origin_requests'] += 1
        
        try:
            # Simulate origin request
            await asyncio.sleep(0.1)  # Simulate network latency
            
            # Return simulated data
            return {
                'key': cache_key,
                'value': f'Data for {cache_key}',
                'timestamp': time.time(),
                'origin': self.origin_url
            }
        except Exception as e:
            print(f"Origin fetch failed: {e}")
            return None
    
    def _make_cache_key(self, key: str) -> str:
        """Generate cache key"""
        return hashlib.md5(key.encode()).hexdigest()
    
    def _generate_etag(self, data: dict) -> str:
        """Generate ETag for data"""
        content = json.dumps(data, sort_keys=True)
        return hashlib.md5(content.encode()).hexdigest()
    
    def get_stats(self) -> dict:
        """Get cache performance statistics"""
        total_requests = self.stats['edge_hits'] + self.stats['edge_misses']
        hit_rate = (self.stats['edge_hits'] / total_requests * 100) if total_requests > 0 else 0
        
        return {
            'node_id': self.node_id,
            'total_requests': total_requests,
            'edge_hit_rate': f"{hit_rate:.1f}%",
            **self.stats
        }

# Test the edge-origin hybrid caching
async def test_edge_origin_cache():
    """
    Test edge-origin hybrid caching with various scenarios
    """
    cache = EdgeOriginCache('edge-us-west', 'https://origin.example.com')
    
    print("ğŸ§ª Testing Edge-Origin Hybrid Caching\n")
    
    # Test 1: Cold cache (cache miss)
    print("Test 1: Cold Cache Miss")
    result = await cache.get('user:12345', ttl=60)
    print(f"Result: {result['source']}, Age: {result.get('age_seconds', 0):.1f}s\n")
    
    # Test 2: Warm cache (cache hit)
    print("Test 2: Warm Cache Hit")
    result = await cache.get('user:12345', ttl=60)
    print(f"Result: {result['source']}, Age: {result.get('age_seconds', 0):.1f}s\n")
    
    # Test 3: Stale-while-revalidate
    print("Test 3: Stale-While-Revalidate")
    # Make cache stale
    cache.cache[cache._make_cache_key('user:12345')].timestamp -= 50
    result = await cache.get('user:12345', ttl=60, stale_while_revalidate=True)
    print(f"Result: {result['source']}, Age: {result.get('age_seconds', 0):.1f}s")
    await asyncio.sleep(0.2)  # Wait for background revalidation
    print(f"Background revalidation completed\n")
    
    # Test 4: Concurrent requests (cache stampede prevention)
    print("Test 4: Concurrent Requests (Stampede Prevention)")
    tasks = [cache.get('popular:item', ttl=120) for _ in range(10)]
    results = await asyncio.gather(*tasks)
    sources = [r['source'] for r in results]
    print(f"10 concurrent requests - Sources: {set(sources)}")
    print(f"Origin requests made: {cache.stats['origin_requests']} (should be 1)\n")
    
    # Print final statistics
    print("ğŸ“Š Cache Performance Statistics:")
    stats = cache.get_stats()
    for key, value in stats.items():
        print(f"   {key}: {value}")

# Run the test
if __name__ == "__main__":
    asyncio.run(test_edge_origin_cache())
```

---

## ğŸ¨ Visual Learning: Edge Computing Architecture

### ğŸŒ Edge Computing Deployment Model
```
Global Edge Computing Architecture:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Control Plane                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Code     â”‚  â”‚  Configurationâ”‚  â”‚   Monitoring   â”‚  â”‚
â”‚  â”‚ Repository â”‚  â”‚   Management  â”‚  â”‚  & Analytics   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ Deploy & Configure
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                Edge Computing Layer                      â”‚
â”‚                                                          â”‚
â”‚  ğŸŒ North America (10 locations)                        â”‚
â”‚  â”œâ”€ us-west-1: 5ms user latency                        â”‚
â”‚  â”œâ”€ us-east-1: 8ms user latency                        â”‚
â”‚  â””â”€ ca-central: 6ms user latency                       â”‚
â”‚                                                          â”‚
â”‚  ğŸŒ Europe (8 locations)                                â”‚
â”‚  â”œâ”€ eu-west-1: 7ms user latency                        â”‚
â”‚  â”œâ”€ eu-central: 9ms user latency                       â”‚
â”‚  â””â”€ eu-north: 12ms user latency                        â”‚
â”‚                                                          â”‚
â”‚  ğŸŒ Asia-Pacific (12 locations)                         â”‚
â”‚  â”œâ”€ asia-se: 6ms user latency                          â”‚
â”‚  â”œâ”€ asia-ne: 8ms user latency                          â”‚
â”‚  â””â”€ oceania: 15ms user latency                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ Fallback for complex operations
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               Regional Cloud Layer                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚Americas  â”‚  â”‚  Europe  â”‚  â”‚   Asia   â”‚             â”‚
â”‚  â”‚50ms RTT  â”‚  â”‚ 45ms RTT â”‚  â”‚ 60ms RTT â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ Heavy processing & storage
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Central Origin Infrastructure                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Database  â”‚  â”‚  ML Training  â”‚  â”‚  Analytics   â”‚  â”‚
â”‚  â”‚  Cluster    â”‚  â”‚   Pipeline    â”‚  â”‚  Warehouse   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Request Processing Flow:
User Request (0ms)
  â†“
Edge Location (5-15ms) â†’ 80% of requests handled here
  â†“ (if needed)
Regional Cloud (50ms) â†’ 15% escalated here
  â†“ (if needed)
Central Origin (100-200ms) â†’ 5% need central processing
```

### ğŸ”„ Anycast BGP Routing
```
BGP Anycast Network Topology:

Same IP Address: 192.0.2.1 announced from multiple locations

           Internet Core Routers
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚           â”‚           â”‚
    â”Œâ”€â”€â”€â”´â”€â”€â”€â”   â”Œâ”€â”€â”€â”´â”€â”€â”€â”   â”Œâ”€â”€â”€â”´â”€â”€â”€â”
    â”‚ ISP A â”‚   â”‚ ISP B â”‚   â”‚ ISP C â”‚
    â”‚  AS1  â”‚   â”‚  AS2  â”‚   â”‚  AS3  â”‚
    â””â”€â”€â”€â”¬â”€â”€â”€â”˜   â””â”€â”€â”€â”¬â”€â”€â”€â”˜   â””â”€â”€â”€â”¬â”€â”€â”€â”˜
        â”‚           â”‚           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”
â”‚       â†“           â†“           â†“       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚Virginia â”‚ â”‚ London  â”‚ â”‚  Tokyo  â”‚ â”‚
â”‚  â”‚ Anycast â”‚ â”‚ Anycast â”‚ â”‚ Anycast â”‚ â”‚
â”‚  â”‚192.0.2.1â”‚ â”‚192.0.2.1â”‚ â”‚192.0.2.1â”‚ â”‚
â”‚  â”‚ AS64512 â”‚ â”‚ AS64513 â”‚ â”‚ AS64514 â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

User in New York queries 192.0.2.1:
â”œâ”€ ISP A routing table sees 3 paths:
â”‚   â”œâ”€ Via AS64512 (Virginia): 2 hops â† Selected!
â”‚   â”œâ”€ Via AS64513 (London): 6 hops
â”‚   â””â”€ Via AS64514 (Tokyo): 12 hops
â”œâ”€ Automatically routes to Virginia
â””â”€ User connects in 20ms

User in London queries 192.0.2.1:
â”œâ”€ ISP B routing table sees 3 paths:
â”‚   â”œâ”€ Via AS64512 (Virginia): 5 hops
â”‚   â”œâ”€ Via AS64513 (London): 1 hop â† Selected!
â”‚   â””â”€ Via AS64514 (Tokyo): 10 hops
â”œâ”€ Automatically routes to London
â””â”€ User connects in 8ms

Benefits:
âœ“ Automatic geographic optimization
âœ“ Instant failover (BGP convergence: 30-180s)
âœ“ DDoS distribution across all locations
âœ“ No DNS dependency for routing
```

### ğŸ“Š Edge vs Cloud Performance
```
Performance Comparison:

Traditional Cloud Architecture:
User (Tokyo) â†’ Internet â†’ Cloud (Virginia) â†’ Response
     â†“            â†“            â†“
   0ms         150ms        20ms (processing)
                           â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                           Total: 170ms

Edge Computing Architecture:
User (Tokyo) â†’ Edge (Tokyo) â†’ Response
     â†“            â†“
   0ms          8ms (processing)
                â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                Total: 8ms

Performance Improvement: 95% faster! (170ms â†’ 8ms)

Cost Comparison (1M requests/month):

Cloud-Only:
â”œâ”€ Compute: 1M requests Ã— $0.20/M = $0.20
â”œâ”€ Data transfer: 100GB Ã— $0.09/GB = $9.00
â”œâ”€ Total: $9.20/month

Edge + Cloud (80% edge, 20% cloud):
â”œâ”€ Edge compute: 800K Ã— $0.50/M = $0.40
â”œâ”€ Edge data transfer: 80GB Ã— $0.01/GB = $0.80
â”œâ”€ Cloud compute: 200K Ã— $0.20/M = $0.04
â”œâ”€ Cloud data transfer: 20GB Ã— $0.09/GB = $1.80
â”œâ”€ Total: $3.04/month

Savings: 67% cost reduction + 95% latency improvement!
```

---

## ğŸ¯ Week 10 Wrap-Up: Edge Computing & Anycast Mastery

### ğŸ§  Mental Models to Internalize

1. **Edge Computing = Local Intelligence**: Process close to users, escalate to cloud when needed
2. **Anycast = Quantum Networking**: Same address exists in multiple places simultaneously
3. **CRDTs = Distributed Harmony**: Data structures that merge automatically without conflicts
4. **Stale-While-Revalidate = Optimistic Caching**: Serve fast, update in background

### ğŸ† Principal Architect Decision Framework

**When to Use Edge Computing:**
- âœ… **Latency-sensitive applications** (gaming, video, real-time collaboration)
- âœ… **High-volume static content** (images, videos, CSS/JS)
- âœ… **Simple business logic** (authentication, routing, transformation)
- âœ… **Geographic compliance** (data must stay in region)

**When to Keep in Cloud:**
- âŒ **Complex stateful operations** (long transactions, heavy computation)
- âŒ **Large database queries** (multi-table joins, analytics)
- âŒ **Machine learning training** (requires GPU clusters)
- âŒ **Rare operations** (batch jobs, admin functions)

### ğŸš¨ Common Edge Computing Mistakes

âŒ **Over-engineering edge logic** = Complex code that belongs in cloud
âŒ **Ignoring state management** = Assuming edge nodes are isolated
âŒ **No fallback strategy** = Edge failures cause complete outages
âŒ **Underestimating costs** = Edge compute can be expensive at high volume
âœ… **Hybrid approach** = Use edge for performance, cloud for functionality

### ğŸ”® Preview: Week 11 - Performance Optimization & Monitoring

Next week we'll dive into performance optimization techniques and monitoring strategies. You'll learn how to measure, analyze, and optimize global systems, and build observability into distributed edge architectures.

---

## ğŸ¤” Reflection Questions

Before moving to Week 11, ensure you can answer:

1. **ELI5**: "Why does TikTok load videos almost instantly no matter where you are, but some websites take forever?"

2. **Architect Level**: "Design an edge computing architecture for a multiplayer gaming platform that needs <20ms latency globally with strong consistency for game state."

3. **Technical Deep-Dive**: "Your anycast network shows good BGP convergence times (60s), but users report 5-minute outages during failures. What could be causing this discrepancy?"

4. **Business Analysis**: "Calculate the ROI of deploying edge computing for an e-commerce platform serving 10M users globally, considering latency improvements, conversion rate impacts, and infrastructure costs."

---

*"Edge computing is not just about speed - it's about fundamentally rethinking where computation happens in our globally distributed world."*

**Next**: [Week 11 - Performance Optimization & Monitoring](11-Week11-Performance-Monitoring.md)